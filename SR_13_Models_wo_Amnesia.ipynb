{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Chapter-13\" data-toc-modified-id=\"Chapter-13-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Chapter 13</a></span><ul class=\"toc-item\"><li><span><a href=\"#Example-Multilevel-Tadpoles\" data-toc-modified-id=\"Example-Multilevel-Tadpoles-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Example Multilevel Tadpoles</a></span></li><li><span><a href=\"#Varying-effects-and-the-underfitting/overfitting-trade-off\" data-toc-modified-id=\"Varying-effects-and-the-underfitting/overfitting-trade-off-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Varying effects and the underfitting/overfitting trade-off</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-model\" data-toc-modified-id=\"The-model-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>The model</a></span></li><li><span><a href=\"#Assign-values-to-the-parameters\" data-toc-modified-id=\"Assign-values-to-the-parameters-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Assign values to the parameters</a></span></li><li><span><a href=\"#Simulate-Survivors\" data-toc-modified-id=\"Simulate-Survivors-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Simulate Survivors</a></span></li><li><span><a href=\"#Compute-the-no-pooling-estimates\" data-toc-modified-id=\"Compute-the-no-pooling-estimates-1.2.4\"><span class=\"toc-item-num\">1.2.4&nbsp;&nbsp;</span>Compute the no-pooling estimates</a></span></li><li><span><a href=\"#Compute-the-partial-pooling-estimates\" data-toc-modified-id=\"Compute-the-partial-pooling-estimates-1.2.5\"><span class=\"toc-item-num\">1.2.5&nbsp;&nbsp;</span>Compute the partial-pooling estimates</a></span></li></ul></li><li><span><a href=\"#More-than-one-type-of-cluster\" data-toc-modified-id=\"More-than-one-type-of-cluster-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>More than one type of cluster</a></span><ul class=\"toc-item\"><li><span><a href=\"#Multilevel-chimpanzees\" data-toc-modified-id=\"Multilevel-chimpanzees-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Multilevel chimpanzees</a></span></li><li><span><a href=\"#Even-more-clusters\" data-toc-modified-id=\"Even-more-clusters-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Even more clusters</a></span></li></ul></li><li><span><a href=\"#Divergent-transitions-and-non-centered-priors\" data-toc-modified-id=\"Divergent-transitions-and-non-centered-priors-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Divergent transitions and non-centered priors</a></span><ul class=\"toc-item\"><li><span><a href=\"#Adjust-target-acceptance\" data-toc-modified-id=\"Adjust-target-acceptance-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>Adjust target acceptance</a></span></li><li><span><a href=\"#Reparameterization\" data-toc-modified-id=\"Reparameterization-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>Reparameterization</a></span></li></ul></li><li><span><a href=\"#Multilevel-posterior-predictions\" data-toc-modified-id=\"Multilevel-posterior-predictions-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Multilevel posterior predictions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Posterior-prediction-for-same-clusters.\" data-toc-modified-id=\"Posterior-prediction-for-same-clusters.-1.5.1\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span>Posterior prediction for same clusters.</a></span></li><li><span><a href=\"#Posterior-prediction-for-new-clusters.\" data-toc-modified-id=\"Posterior-prediction-for-new-clusters.-1.5.2\"><span class=\"toc-item-num\">1.5.2&nbsp;&nbsp;</span>Posterior prediction for new clusters.</a></span></li></ul></li><li><span><a href=\"#Practice-Problems\" data-toc-modified-id=\"Practice-Problems-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Practice Problems</a></span></li></ul></li><li><span><a href=\"#---\" data-toc-modified-id=\"----2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>---</a></span></li><li><span><a href=\"#Misc\" data-toc-modified-id=\"Misc-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Misc</a></span><ul class=\"toc-item\"><li><span><a href=\"#How-link-works\" data-toc-modified-id=\"How-link-works-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>How link works</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-- Attaching packages --------------------------------------- tidyverse 1.2.1 --\n",
      "v ggplot2 3.1.0       v purrr   0.3.0  \n",
      "v tibble  2.0.1       v dplyr   0.8.0.1\n",
      "v tidyr   0.8.2       v stringr 1.4.0  \n",
      "v readr   1.3.1       v forcats 0.4.0  \n",
      "Warning message:\n",
      "\"package 'tibble' was built under R version 3.5.2\"Warning message:\n",
      "\"package 'readr' was built under R version 3.5.2\"Warning message:\n",
      "\"package 'purrr' was built under R version 3.5.2\"Warning message:\n",
      "\"package 'dplyr' was built under R version 3.5.2\"Warning message:\n",
      "\"package 'stringr' was built under R version 3.5.2\"Warning message:\n",
      "\"package 'forcats' was built under R version 3.5.2\"-- Conflicts ------------------------------------------ tidyverse_conflicts() --\n",
      "x dplyr::filter() masks stats::filter()\n",
      "x dplyr::lag()    masks stats::lag()\n",
      "Loading required package: rstan\n",
      "Loading required package: StanHeaders\n",
      "Warning message:\n",
      "\"package 'StanHeaders' was built under R version 3.5.2\"rstan (Version 2.18.2, GitRev: 2e1f913d3ca3)\n",
      "For execution on a local, multicore CPU with excess RAM we recommend calling\n",
      "options(mc.cores = parallel::detectCores()).\n",
      "To avoid recompilation of unchanged Stan programs, we recommend calling\n",
      "rstan_options(auto_write = TRUE)\n",
      "For improved execution time, we recommend calling\n",
      "Sys.setenv(LOCAL_CPPFLAGS = '-march=native')\n",
      "although this causes Stan to throw an error on a few processors.\n",
      "\n",
      "Attaching package: 'rstan'\n",
      "\n",
      "The following object is masked from 'package:tidyr':\n",
      "\n",
      "    extract\n",
      "\n",
      "Loading required package: parallel\n",
      "rethinking (Version 1.84)\n",
      "\n",
      "Attaching package: 'rethinking'\n",
      "\n",
      "The following object is masked from 'package:purrr':\n",
      "\n",
      "    map\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "\n",
    "# loads experimental branch of statistical rethinking pkg\n",
    "library(rethinking, lib = \"C:/Users/bings/Documents/R/test-library\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Multilevel Tadpoles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **<font color = 'purple' style='background-color: lightyellow'>Here is a model for predicting tadpole mortality in each tank, using the regularizing priors of earlier chapters:</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='pics/SR_r31.png' alt='Drawing' style='width:525pt'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t48 obs. of  5 variables:\n",
      " $ density : int  10 10 10 10 10 10 10 10 10 10 ...\n",
      " $ pred    : Factor w/ 2 levels \"no\",\"pred\": 1 1 1 1 1 1 1 1 2 2 ...\n",
      " $ size    : Factor w/ 2 levels \"big\",\"small\": 1 1 1 1 2 2 2 2 1 1 ...\n",
      " $ surv    : int  9 10 7 10 9 9 10 9 4 9 ...\n",
      " $ propsurv: num  0.9 1 0.7 1 0.9 0.9 1 0.9 0.4 0.9 ...\n"
     ]
    }
   ],
   "source": [
    "data(reedfrogs)\n",
    "d <- reedfrogs\n",
    "str(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>density</th><th scope=col>pred</th><th scope=col>size</th><th scope=col>surv</th><th scope=col>propsurv</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>10   </td><td>no   </td><td>big  </td><td> 9   </td><td>0.9  </td></tr>\n",
       "\t<tr><td>10   </td><td>no   </td><td>big  </td><td>10   </td><td>1.0  </td></tr>\n",
       "\t<tr><td>10   </td><td>no   </td><td>big  </td><td> 7   </td><td>0.7  </td></tr>\n",
       "\t<tr><td>10   </td><td>no   </td><td>big  </td><td>10   </td><td>1.0  </td></tr>\n",
       "\t<tr><td>10   </td><td>no   </td><td>small</td><td> 9   </td><td>0.9  </td></tr>\n",
       "\t<tr><td>10   </td><td>no   </td><td>small</td><td> 9   </td><td>0.9  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " density & pred & size & surv & propsurv\\\\\n",
       "\\hline\n",
       "\t 10    & no    & big   &  9    & 0.9  \\\\\n",
       "\t 10    & no    & big   & 10    & 1.0  \\\\\n",
       "\t 10    & no    & big   &  7    & 0.7  \\\\\n",
       "\t 10    & no    & big   & 10    & 1.0  \\\\\n",
       "\t 10    & no    & small &  9    & 0.9  \\\\\n",
       "\t 10    & no    & small &  9    & 0.9  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| density | pred | size | surv | propsurv |\n",
       "|---|---|---|---|---|\n",
       "| 10    | no    | big   |  9    | 0.9   |\n",
       "| 10    | no    | big   | 10    | 1.0   |\n",
       "| 10    | no    | big   |  7    | 0.7   |\n",
       "| 10    | no    | big   | 10    | 1.0   |\n",
       "| 10    | no    | small |  9    | 0.9   |\n",
       "| 10    | no    | small |  9    | 0.9   |\n",
       "\n"
      ],
      "text/plain": [
       "  density pred size  surv propsurv\n",
       "1 10      no   big    9   0.9     \n",
       "2 10      no   big   10   1.0     \n",
       "3 10      no   big    7   0.7     \n",
       "4 10      no   big   10   1.0     \n",
       "5 10      no   small  9   0.9     \n",
       "6 10      no   small  9   0.9     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d %>% head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## R code 13.2\n",
    "# make the tank cluster variable\n",
    "d$tank <- 1:nrow(d)\n",
    "\n",
    "dat <- list(\n",
    "    S = d$surv,\n",
    "    N = d$density,\n",
    "    tank = d$tank )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAMPLING FOR MODEL 'cb3dfdd4abafffee16ea86593d6ba62d' NOW (CHAIN 1).\n",
      "Chain 1: \n",
      "Chain 1: Gradient evaluation took 0 seconds\n",
      "Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 1: Adjust your expectations accordingly!\n",
      "Chain 1: \n",
      "Chain 1: \n",
      "Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Chain 1: Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Chain 1: Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Chain 1: Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Chain 1: Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "Chain 1: \n",
      "Chain 1:  Elapsed Time: 0.16 seconds (Warm-up)\n",
      "Chain 1:                0.136 seconds (Sampling)\n",
      "Chain 1:                0.296 seconds (Total)\n",
      "Chain 1: \n",
      "\n",
      "SAMPLING FOR MODEL 'cb3dfdd4abafffee16ea86593d6ba62d' NOW (CHAIN 2).\n",
      "Chain 2: \n",
      "Chain 2: Gradient evaluation took 0 seconds\n",
      "Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 2: Adjust your expectations accordingly!\n",
      "Chain 2: \n",
      "Chain 2: \n",
      "Chain 2: Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Chain 2: Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Chain 2: Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Chain 2: Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Chain 2: Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Chain 2: Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Chain 2: Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Chain 2: Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Chain 2: Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Chain 2: Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Chain 2: Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Chain 2: Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "Chain 2: \n",
      "Chain 2:  Elapsed Time: 0.157 seconds (Warm-up)\n",
      "Chain 2:                0.134 seconds (Sampling)\n",
      "Chain 2:                0.291 seconds (Total)\n",
      "Chain 2: \n",
      "\n",
      "SAMPLING FOR MODEL 'cb3dfdd4abafffee16ea86593d6ba62d' NOW (CHAIN 3).\n",
      "Chain 3: \n",
      "Chain 3: Gradient evaluation took 0 seconds\n",
      "Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 3: Adjust your expectations accordingly!\n",
      "Chain 3: \n",
      "Chain 3: \n",
      "Chain 3: Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Chain 3: Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Chain 3: Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Chain 3: Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Chain 3: Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Chain 3: Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Chain 3: Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Chain 3: Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Chain 3: Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Chain 3: Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Chain 3: Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Chain 3: Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "Chain 3: \n",
      "Chain 3:  Elapsed Time: 0.148 seconds (Warm-up)\n",
      "Chain 3:                0.131 seconds (Sampling)\n",
      "Chain 3:                0.279 seconds (Total)\n",
      "Chain 3: \n",
      "\n",
      "SAMPLING FOR MODEL 'cb3dfdd4abafffee16ea86593d6ba62d' NOW (CHAIN 4).\n",
      "Chain 4: \n",
      "Chain 4: Gradient evaluation took 0 seconds\n",
      "Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 4: Adjust your expectations accordingly!\n",
      "Chain 4: \n",
      "Chain 4: \n",
      "Chain 4: Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Chain 4: Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Chain 4: Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Chain 4: Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Chain 4: Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Chain 4: Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Chain 4: Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Chain 4: Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Chain 4: Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Chain 4: Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Chain 4: Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Chain 4: Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "Chain 4: \n",
      "Chain 4:  Elapsed Time: 0.147 seconds (Warm-up)\n",
      "Chain 4:                0.139 seconds (Sampling)\n",
      "Chain 4:                0.286 seconds (Total)\n",
      "Chain 4: \n"
     ]
    }
   ],
   "source": [
    "# approximate posterior\n",
    "m13.1 <- ulam(\n",
    "    alist(\n",
    "        S ~ dbinom( N , p ) ,\n",
    "        logit(p) <- a[tank] ,\n",
    "        a[tank] ~ dnorm( 0 , 1.5 )\n",
    "    ), data=dat , chains=4 , log_lik=TRUE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "precis(m13.1,depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **<font color = 'purple' style='background-color: lightyellow'>Now let’s do the multilevel model, which adaptively pools information across tanks</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that is required to enable adaptive pooling is to make the prior for the a parameters a function of some new parameters. Here is the multilevel model, in mathematical form, with the changes from the previous model highlighted in blue:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='pics/SR_r32.png' alt='Drawing' style='width:525pt'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the prior for the tank intercepts is now a function of two parameters, $\\bar{α}$ and σ. You can say $\\bar{α}$ like “bar alpha.” The bar means average. These two parameters inside the prior is where the “multi” in multilevel arises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in file(con, \"w\"):\n",
      "\"cannot open file 'C:\\Users\\bings\\AppData\\Local\\Temp\\Rtmp8YnaDH\\file2efc2d7d3dec': No such file or directory\""
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in file(con, \"w\"): cannot open the connection\n",
     "output_type": "error",
     "traceback": [
      "Error in file(con, \"w\"): cannot open the connection\nTraceback:\n",
      "1. ulam(alist(S ~ dbinom(N, p), logit(p) <- a[tank], a[tank] ~ dnorm(a_bar, \n .     sigma), a_bar ~ dnorm(0, 1.5), sigma ~ dexp(1)), data = dat, \n .     chains = 4, log_lik = TRUE)",
      "2. stan(model_code = model_code, data = data, pars = use_pars, chains = chains, \n .     cores = cores, iter = iter, control = control, ...)",
      "3. stan_model(file, model_name = model_name, model_code = model_code, \n .     stanc_ret = NULL, boost_lib = boost_lib, eigen_lib = eigen_lib, \n .     save_dso = save_dso, verbose = verbose)",
      "4. writeLines(model_code, con = tf)",
      "5. file(con, \"w\")"
     ]
    }
   ],
   "source": [
    "## R code 13.3\n",
    "m13.2 <- ulam(\n",
    "    alist(\n",
    "        S ~ dbinom( N , p ) ,\n",
    "        logit(p) <- a[tank] ,\n",
    "        a[tank] ~ dnorm( a_bar , sigma ) ,\n",
    "        a_bar ~ dnorm( 0 , 1.5 ) ,\n",
    "        sigma ~ dexp( 1 )\n",
    "    ), data=dat , chains=4 , log_lik=TRUE )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model provides posterior distributions for 50 parameters: one overall sample intercept $\\bar{α}$, the standard deviation among tanks σ, and then 48 per-tank intercepts. Let’s check WAIC though to see the effective number of parameters. We’ll compare the earlier model, m13.1, with the new multilevel model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in precis(m13.2, depth = 2): object 'm13.2' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in precis(m13.2, depth = 2): object 'm13.2' not found\nTraceback:\n",
      "1. precis(m13.2, depth = 2) %>% round(2)",
      "2. eval(lhs, parent, parent)",
      "3. eval(lhs, parent, parent)",
      "4. precis(m13.2, depth = 2)"
     ]
    }
   ],
   "source": [
    "precis(m13.2,depth=2) %>% round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model provides posterior distributions for 50 parameters: one overall sample intercept α¯, the standard deviation among tanks σ, and then 48 per-tank intercepts. Let’s check WAIC though to see the effective number of parameters. We’ll compare the earlier model, m13.1, with the new multilevel model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in compare(m13.1, m13.2): object 'm13.1' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in compare(m13.1, m13.2): object 'm13.1' not found\nTraceback:\n",
      "1. compare(m13.1, m13.2) %>% round(2)",
      "2. eval(lhs, parent, parent)",
      "3. eval(lhs, parent, parent)",
      "4. compare(m13.1, m13.2)"
     ]
    }
   ],
   "source": [
    "## R code 13.4\n",
    "compare( m13.1 , m13.2 ) %>% round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color = 'purple'>There are two facts to note here.  </font>** \n",
    "\n",
    "**<font color = 'purple'>First </font>**, **the multilevel model has only 22 effective parameters**. <font color = 'blue'>There are 28 fewer effective parameters than actual parameters, because the prior assigned to each intercept shrinks them all towards the mean $\\bar{α}$</font>. \n",
    "\n",
    "In this case, the prior is reasonably strong. Check the mean of sigma with precis and you’ll see it’s around 1.6. <font color = 'blue'>This is a regularizing prior, like you’ve used in previous chapters, but now the amount of regularization has been learned from the data itself.</font>\n",
    "\n",
    "* **Note** that there is still uncertainty about the regularization. So this model isn’t exactly the same as just assuming a regularizing prior with a constant standard deviation 1.6. Instead the intercepts for each tank average over the uncertainty in σ (and $\\bar{α}$)\n",
    "\n",
    "**<font color = 'purple'>Second </font>**, **notice that the multilevel model m13.2 has fewer effective parameters than the ordinary fixed model m13.1**. This is despite the fact that the ordinary model has fewer actual parameters, only 48 instead of 50. \n",
    "\n",
    "* The extra two parameters in the multilevel model allowed it to learn a more aggressive regularizing prior, to adaptively regularize. This resulted in a less flexible posterior and therefore fewer effective parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in extract.samples(m13.2): object 'm13.2' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in extract.samples(m13.2): object 'm13.2' not found\nTraceback:\n",
      "1. extract.samples(m13.2)"
     ]
    }
   ],
   "source": [
    "## R code 13.5\n",
    "# extract Stan samples\n",
    "post <- extract.samples(m13.2)\n",
    "\n",
    "# compute median intercept for each tank\n",
    "# also transform to probability with logistic\n",
    "d$propsurv.est <- logistic( apply( post$a , 2 , mean ) )\n",
    "\n",
    "# display raw proportions surviving in each tank\n",
    "plot( d$propsurv , ylim=c(0,1) , pch=16 , xaxt=\"n\" ,\n",
    "    xlab=\"tank\" , ylab=\"proportion survival\" , col=rangi2 )\n",
    "axis( 1 , at=c(1,16,32,48) , labels=c(1,16,32,48) )\n",
    "\n",
    "# overlay posterior means\n",
    "points( d$propsurv.est )\n",
    "\n",
    "# mark posterior mean probability across tanks\n",
    "abline( h=mean(inv_logit(post$a_bar)) , lty=2 )\n",
    "\n",
    "# draw vertical dividers between tank densities\n",
    "abline( v=16.5 , lwd=0.5 )\n",
    "abline( v=32.5 , lwd=0.5 )\n",
    "text( 8 , 0 , \"small tanks\" )\n",
    "text( 16+8 , 0 , \"medium tanks\" )\n",
    "text( 32+8 , 0 , \"large tanks\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "## R code 13.6\n",
    "# show first 100 populations in the posterior\n",
    "plot( NULL , xlim=c(-3,4) , ylim=c(0,0.35) ,\n",
    "    xlab=\"log-odds survive\" , ylab=\"Density\" )\n",
    "\n",
    "for ( i in 1:100 )\n",
    "    curve( dnorm(x,post$a_bar[i],post$sigma[i]) , add=TRUE ,\n",
    "    col=col.alpha(\"black\",0.2) )\n",
    "\n",
    "# sample 8000 imaginary tanks from the posterior distribution\n",
    "sim_tanks <- rnorm( 8000 , post$a_bar , post$sigma )\n",
    "\n",
    "# transform to probability and visualize\n",
    "dens( inv_logit(sim_tanks) , lwd=2 , adj=0.1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying effects and the underfitting/overfitting trade-off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='pics/SR_r33.png' alt='Drawing' style='width:425pt'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign values to the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## R code 13.7\n",
    "a_bar <- 1.5\n",
    "sigma <- 1.5\n",
    "nponds <- 60\n",
    "\n",
    "# sample size N_i in each pond.\n",
    "Ni <- as.integer( rep( c(5,10,25,35) , each=15 ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>5</li>\n",
       "\t<li>5</li>\n",
       "\t<li>5</li>\n",
       "\t<li>5</li>\n",
       "\t<li>5</li>\n",
       "\t<li>5</li>\n",
       "\t<li>5</li>\n",
       "\t<li>5</li>\n",
       "\t<li>5</li>\n",
       "\t<li>5</li>\n",
       "\t<li>5</li>\n",
       "\t<li>5</li>\n",
       "\t<li>5</li>\n",
       "\t<li>5</li>\n",
       "\t<li>5</li>\n",
       "\t<li>10</li>\n",
       "\t<li>10</li>\n",
       "\t<li>10</li>\n",
       "\t<li>10</li>\n",
       "\t<li>10</li>\n",
       "\t<li>10</li>\n",
       "\t<li>10</li>\n",
       "\t<li>10</li>\n",
       "\t<li>10</li>\n",
       "\t<li>10</li>\n",
       "\t<li>10</li>\n",
       "\t<li>10</li>\n",
       "\t<li>10</li>\n",
       "\t<li>10</li>\n",
       "\t<li>10</li>\n",
       "\t<li>25</li>\n",
       "\t<li>25</li>\n",
       "\t<li>25</li>\n",
       "\t<li>25</li>\n",
       "\t<li>25</li>\n",
       "\t<li>25</li>\n",
       "\t<li>25</li>\n",
       "\t<li>25</li>\n",
       "\t<li>25</li>\n",
       "\t<li>25</li>\n",
       "\t<li>25</li>\n",
       "\t<li>25</li>\n",
       "\t<li>25</li>\n",
       "\t<li>25</li>\n",
       "\t<li>25</li>\n",
       "\t<li>35</li>\n",
       "\t<li>35</li>\n",
       "\t<li>35</li>\n",
       "\t<li>35</li>\n",
       "\t<li>35</li>\n",
       "\t<li>35</li>\n",
       "\t<li>35</li>\n",
       "\t<li>35</li>\n",
       "\t<li>35</li>\n",
       "\t<li>35</li>\n",
       "\t<li>35</li>\n",
       "\t<li>35</li>\n",
       "\t<li>35</li>\n",
       "\t<li>35</li>\n",
       "\t<li>35</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 5\n",
       "\\item 5\n",
       "\\item 5\n",
       "\\item 5\n",
       "\\item 5\n",
       "\\item 5\n",
       "\\item 5\n",
       "\\item 5\n",
       "\\item 5\n",
       "\\item 5\n",
       "\\item 5\n",
       "\\item 5\n",
       "\\item 5\n",
       "\\item 5\n",
       "\\item 5\n",
       "\\item 10\n",
       "\\item 10\n",
       "\\item 10\n",
       "\\item 10\n",
       "\\item 10\n",
       "\\item 10\n",
       "\\item 10\n",
       "\\item 10\n",
       "\\item 10\n",
       "\\item 10\n",
       "\\item 10\n",
       "\\item 10\n",
       "\\item 10\n",
       "\\item 10\n",
       "\\item 10\n",
       "\\item 25\n",
       "\\item 25\n",
       "\\item 25\n",
       "\\item 25\n",
       "\\item 25\n",
       "\\item 25\n",
       "\\item 25\n",
       "\\item 25\n",
       "\\item 25\n",
       "\\item 25\n",
       "\\item 25\n",
       "\\item 25\n",
       "\\item 25\n",
       "\\item 25\n",
       "\\item 25\n",
       "\\item 35\n",
       "\\item 35\n",
       "\\item 35\n",
       "\\item 35\n",
       "\\item 35\n",
       "\\item 35\n",
       "\\item 35\n",
       "\\item 35\n",
       "\\item 35\n",
       "\\item 35\n",
       "\\item 35\n",
       "\\item 35\n",
       "\\item 35\n",
       "\\item 35\n",
       "\\item 35\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 5\n",
       "2. 5\n",
       "3. 5\n",
       "4. 5\n",
       "5. 5\n",
       "6. 5\n",
       "7. 5\n",
       "8. 5\n",
       "9. 5\n",
       "10. 5\n",
       "11. 5\n",
       "12. 5\n",
       "13. 5\n",
       "14. 5\n",
       "15. 5\n",
       "16. 10\n",
       "17. 10\n",
       "18. 10\n",
       "19. 10\n",
       "20. 10\n",
       "21. 10\n",
       "22. 10\n",
       "23. 10\n",
       "24. 10\n",
       "25. 10\n",
       "26. 10\n",
       "27. 10\n",
       "28. 10\n",
       "29. 10\n",
       "30. 10\n",
       "31. 25\n",
       "32. 25\n",
       "33. 25\n",
       "34. 25\n",
       "35. 25\n",
       "36. 25\n",
       "37. 25\n",
       "38. 25\n",
       "39. 25\n",
       "40. 25\n",
       "41. 25\n",
       "42. 25\n",
       "43. 25\n",
       "44. 25\n",
       "45. 25\n",
       "46. 35\n",
       "47. 35\n",
       "48. 35\n",
       "49. 35\n",
       "50. 35\n",
       "51. 35\n",
       "52. 35\n",
       "53. 35\n",
       "54. 35\n",
       "55. 35\n",
       "56. 35\n",
       "57. 35\n",
       "58. 35\n",
       "59. 35\n",
       "60. 35\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1]  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5 10 10 10 10 10 10 10 10 10 10\n",
       "[26] 10 10 10 10 10 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 35 35 35 35 35\n",
       "[51] 35 35 35 35 35 35 35 35 35 35"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Ni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values $\\bar{α}$ = 1.4 and σ = 1.5 define a Gaussian distribution of individual pond logodds of survival."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we need to simulate all 60 of these intercept values from the implied Gaussian distribution with mean $\\bar{α}$ and standard deviation σ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(5005)\n",
    "a_pond <- rnorm( nponds , mean=a_bar , sd=sigma )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead and inspect the contents of a_pond. It should contain 60 log-odds values, one for each simulated pond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0.566731225916697</li>\n",
       "\t<li>1.99002317494446</li>\n",
       "\t<li>-0.13775687859197</li>\n",
       "\t<li>1.85676650932582</li>\n",
       "\t<li>3.91208799855199</li>\n",
       "\t<li>1.95414869415232</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.566731225916697\n",
       "\\item 1.99002317494446\n",
       "\\item -0.13775687859197\n",
       "\\item 1.85676650932582\n",
       "\\item 3.91208799855199\n",
       "\\item 1.95414869415232\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.566731225916697\n",
       "2. 1.99002317494446\n",
       "3. -0.13775687859197\n",
       "4. 1.85676650932582\n",
       "5. 3.91208799855199\n",
       "6. 1.95414869415232\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  0.5667312  1.9900232 -0.1377569  1.8567665  3.9120880  1.9541487"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a_pond %>% head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let’s bundle some of this information in a data frame, \n",
    "# just to keep it organized.\n",
    "dsim <- data.frame( pond=1:nponds , Ni=Ni , true_a=a_pond )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column is the pond index, 1 through 60. The second column is the initial tadpole count in each pond. The third column is the true log-odds survival for each pond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>pond</th><th scope=col>Ni</th><th scope=col>true_a</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1         </td><td>5         </td><td> 0.5667312</td></tr>\n",
       "\t<tr><td>2         </td><td>5         </td><td> 1.9900232</td></tr>\n",
       "\t<tr><td>3         </td><td>5         </td><td>-0.1377569</td></tr>\n",
       "\t<tr><td>4         </td><td>5         </td><td> 1.8567665</td></tr>\n",
       "\t<tr><td>5         </td><td>5         </td><td> 3.9120880</td></tr>\n",
       "\t<tr><td>6         </td><td>5         </td><td> 1.9541487</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " pond & Ni & true\\_a\\\\\n",
       "\\hline\n",
       "\t 1          & 5          &  0.5667312\\\\\n",
       "\t 2          & 5          &  1.9900232\\\\\n",
       "\t 3          & 5          & -0.1377569\\\\\n",
       "\t 4          & 5          &  1.8567665\\\\\n",
       "\t 5          & 5          &  3.9120880\\\\\n",
       "\t 6          & 5          &  1.9541487\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| pond | Ni | true_a |\n",
       "|---|---|---|\n",
       "| 1          | 5          |  0.5667312 |\n",
       "| 2          | 5          |  1.9900232 |\n",
       "| 3          | 5          | -0.1377569 |\n",
       "| 4          | 5          |  1.8567665 |\n",
       "| 5          | 5          |  3.9120880 |\n",
       "| 6          | 5          |  1.9541487 |\n",
       "\n"
      ],
      "text/plain": [
       "  pond Ni true_a    \n",
       "1 1    5   0.5667312\n",
       "2 2    5   1.9900232\n",
       "3 3    5  -0.1377569\n",
       "4 4    5   1.8567665\n",
       "5 5    5   3.9120880\n",
       "6 6    5   1.9541487"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dsim %>% head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate Survivors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='pics/SR_r34.png' alt='Drawing' style='width:425pt'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color = 'purple'>Putting the logistic into the random binomial function, we can generate a simulated survivor count for each pond: </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulated survivor count\n",
    "dsim$Si <- rbinom( nponds , prob=logistic(dsim$true_a) , size=dsim$Ni )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>pond</th><th scope=col>Ni</th><th scope=col>true_a</th><th scope=col>Si</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>55</th><td>55       </td><td>35       </td><td>0.5651822</td><td>26       </td></tr>\n",
       "\t<tr><th scope=row>56</th><td>56       </td><td>35       </td><td>2.5580613</td><td>33       </td></tr>\n",
       "\t<tr><th scope=row>57</th><td>57       </td><td>35       </td><td>0.5674268</td><td>23       </td></tr>\n",
       "\t<tr><th scope=row>58</th><td>58       </td><td>35       </td><td>2.7460641</td><td>35       </td></tr>\n",
       "\t<tr><th scope=row>59</th><td>59       </td><td>35       </td><td>1.5042225</td><td>29       </td></tr>\n",
       "\t<tr><th scope=row>60</th><td>60       </td><td>35       </td><td>2.4973795</td><td>32       </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       "  & pond & Ni & true\\_a & Si\\\\\n",
       "\\hline\n",
       "\t55 & 55        & 35        & 0.5651822 & 26       \\\\\n",
       "\t56 & 56        & 35        & 2.5580613 & 33       \\\\\n",
       "\t57 & 57        & 35        & 0.5674268 & 23       \\\\\n",
       "\t58 & 58        & 35        & 2.7460641 & 35       \\\\\n",
       "\t59 & 59        & 35        & 1.5042225 & 29       \\\\\n",
       "\t60 & 60        & 35        & 2.4973795 & 32       \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | pond | Ni | true_a | Si |\n",
       "|---|---|---|---|---|\n",
       "| 55 | 55        | 35        | 0.5651822 | 26        |\n",
       "| 56 | 56        | 35        | 2.5580613 | 33        |\n",
       "| 57 | 57        | 35        | 0.5674268 | 23        |\n",
       "| 58 | 58        | 35        | 2.7460641 | 35        |\n",
       "| 59 | 59        | 35        | 1.5042225 | 29        |\n",
       "| 60 | 60        | 35        | 2.4973795 | 32        |\n",
       "\n"
      ],
      "text/plain": [
       "   pond Ni true_a    Si\n",
       "55 55   35 0.5651822 26\n",
       "56 56   35 2.5580613 33\n",
       "57 57   35 0.5674268 23\n",
       "58 58   35 2.7460641 35\n",
       "59 59   35 1.5042225 29\n",
       "60 60   35 2.4973795 32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dsim %>% tail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual with R, if you give it a list of values, it returns a new list of the same length. \n",
    "\n",
    "<font color = 'green'>In the above, each paired $α_i$(`dsim$true_a`) and Ni (`dsim$Ni`) is used to generate a random survivor count with the appropriate probability of survival and maximum count. These counts are stored in a new column in `dsim$Si`</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the no-pooling estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’re ready to start analyzing the simulated data now. **<font color = 'purple' style='background-color: lightyellow'>The easiest task is to just compute the no-pooling estimates</font>**. \n",
    "\n",
    "* We can accomplish this straight from the empirical data, just by calculating the proportion of survivors in each pond. \n",
    "\n",
    "I’ll keep these estimates on the probability scale, instead of translating them to the log-odds scale, because we’ll want to compare the quality of the estimates on the probability scale later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsim$p_nopool <- dsim$Si / dsim$Ni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0.8</li>\n",
       "\t<li>1</li>\n",
       "\t<li>0.2</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.8\n",
       "\\item 1\n",
       "\\item 0.2\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.8\n",
       "2. 1\n",
       "3. 0.2\n",
       "4. 1\n",
       "5. 1\n",
       "6. 1\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.8 1.0 0.2 1.0 1.0 1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dsim$p_nopool %>% head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'blue'>Now there’s another column in dsim, containing the empirical proportions of survivors in each pond. \n",
    "    \n",
    "*     These are the same no-pooling estimates you’d get by fitting a model with a dummy variable for each pond and flat priors that induce no regularization</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the partial-pooling estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to fit the model to the simulated data, using map2stan. I’ll use a single long chain in this example, but keep in mind that you need to use multiple chains to check convergence to the right posterior distribution. In this case, it’s safe. But don’t get cocky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in file(con, \"w\"):\n",
      "\"cannot open file 'C:\\Users\\bings\\AppData\\Local\\Temp\\Rtmp8YnaDH\\file2efc373a6daa': No such file or directory\""
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in file(con, \"w\"): cannot open the connection\n",
     "output_type": "error",
     "traceback": [
      "Error in file(con, \"w\"): cannot open the connection\nTraceback:\n",
      "1. ulam(alist(Si ~ dbinom(Ni, p), logit(p) <- a_pond[pond], a_pond[pond] ~ \n .     dnorm(a_bar, sigma), a_bar ~ dnorm(0, 1.5), sigma ~ dexp(1)), \n .     data = dat, chains = 4)",
      "2. stan(model_code = model_code, data = data, pars = use_pars, chains = chains, \n .     cores = cores, iter = iter, control = control, ...)",
      "3. stan_model(file, model_name = model_name, model_code = model_code, \n .     stanc_ret = NULL, boost_lib = boost_lib, eigen_lib = eigen_lib, \n .     save_dso = save_dso, verbose = verbose)",
      "4. writeLines(model_code, con = tf)",
      "5. file(con, \"w\")"
     ]
    }
   ],
   "source": [
    "## R code 13.13\n",
    "dat <- list( Si=dsim$Si , Ni=dsim$Ni , pond=dsim$pond )\n",
    "m13.3 <- ulam(\n",
    "    alist(\n",
    "        Si ~ dbinom( Ni , p ),\n",
    "        logit(p) <- a_pond[pond],\n",
    "        a_pond[pond] ~ dnorm( a_bar , sigma ),\n",
    "        a_bar ~ dnorm( 0 , 1.5 ),\n",
    "        sigma ~ dexp( 1 )\n",
    "    ), data=dat , chains=4 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve fit the basic varying intercept model above. You can take a look at the estimates for α¯ and σ with the usual precis approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in precis(m13.3, depth = 2): object 'm13.3' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in precis(m13.3, depth = 2): object 'm13.3' not found\nTraceback:\n",
      "1. precis(m13.3, depth = 2) %>% round(2)",
      "2. eval(lhs, parent, parent)",
      "3. eval(lhs, parent, parent)",
      "4. precis(m13.3, depth = 2)"
     ]
    }
   ],
   "source": [
    " precis( m13.3 , depth=2 ) %>% round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color = 'purple' style='background-color: lightyellow'>Now let’s compute the predicted survival proportions and add those proportions to our growing simulation data frame</font>**. To indicate that it contains the partial pooling estimates, I’ll call the column `p_partpool`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in extract.samples(m13.3): object 'm13.3' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in extract.samples(m13.3): object 'm13.3' not found\nTraceback:\n",
      "1. extract.samples(m13.3)"
     ]
    }
   ],
   "source": [
    "post <- extract.samples( m13.3 )\n",
    "post$a_pond %>% dim()\n",
    "post %>% length()\n",
    "post %>% str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post <- extract.samples( m13.3 )\n",
    "dsim$p_partpool <- apply( inv_logit(post$a_pond) , 2 , mean )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsim %>% head(2)\n",
    "'------'\n",
    "post$a_pond %>% dim()\n",
    "post$a_pond %>% head(2)\n",
    "\n",
    "'------'\n",
    "\n",
    "inv_logit(post$a_pond) %>% head(2) \n",
    "\n",
    "'--'\n",
    "\n",
    "inv_logit(post$a_pond)[,1]  %>% mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to compare to the **<font color = 'purple' style='background-color: lightyellow'>true per-pond survival probabilities</font>** used to generate the data, then we’ll also need to compute those, using the true_a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsim$p_true <- inv_logit( dsim$true_a )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we need to do, before we can plot the results and realize the point of this lesson, is to **<font color = 'purple' style='background-color: lightyellow'>compute the absolute error between the estimates and the true varying effects</font>**. This is easy enough, using the existing columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nopool_error <- abs( dsim$p_nopool - dsim$p_true )\n",
    "partpool_error <- abs( dsim$p_partpool - dsim$p_true )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in xy.coords(x, y): 'x' and 'y' lengths differ\n",
     "output_type": "error",
     "traceback": [
      "Error in xy.coords(x, y): 'x' and 'y' lengths differ\nTraceback:\n",
      "1. points(1:60, partpool_error)",
      "2. points.default(1:60, partpool_error)",
      "3. plot.xy(xy.coords(x, y), type = type, ...)",
      "4. xy.coords(x, y)",
      "5. stop(\"'x' and 'y' lengths differ\")"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in png(tf, width, height, \"in\", pointsize, bg, res, antialias = antialias): unable to start png() device\n",
     "output_type": "error",
     "traceback": [
      "Error in png(tf, width, height, \"in\", pointsize, bg, res, antialias = antialias): unable to start png() device\nTraceback:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width=7.59, repr.plot.height=4)\n",
    "\n",
    "plot( 1:60 , nopool_error , xlab=\"pond\" , ylab=\"absolute error\" ,\n",
    "col=rangi2 , pch=16 )\n",
    "points( 1:60 , partpool_error )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More than one type of cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilevel chimpanzees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the mathematical form of the model, with the new pieces of the machine highlighted in blue:\n",
    "<img src='pics/SR_r35.png' alt='Drawing' style='width:425pt'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## R code 13.21\n",
    "# library(rethinking)\n",
    "data(chimpanzees)\n",
    "d <- chimpanzees\n",
    "d$treatment <- 1 + d$prosoc_left + 2*d$condition\n",
    "\n",
    "dat_list <- list(\n",
    "    pulled_left = d$pulled_left,\n",
    "    actor = d$actor,\n",
    "    block_id = d$block,\n",
    "    treatment = as.integer(d$treatment) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " int [1:504] 1 1 1 1 1 1 1 1 1 1 ...\n"
     ]
    }
   ],
   "source": [
    "d$actor %>% str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"There were 4 divergent transitions after warmup. Increasing adapt_delta above 0.95 may help. See\n",
      "http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\"Warning message:\n",
      "\"Examine the pairs() plot to diagnose sampling problems\n",
      "\""
     ]
    }
   ],
   "source": [
    "set.seed(13)\n",
    "m13.4 <- ulam(\n",
    "    alist(\n",
    "        pulled_left ~ dbinom( 1 , p ) ,\n",
    "        logit(p) <- a[actor] + g[block_id] + b[treatment] ,\n",
    "        b[treatment] ~ dnorm( 0 , 0.5 ),\n",
    "        # adaptive priors\n",
    "        a[actor] ~ dnorm( a_bar , sigma_a ),\n",
    "        g[block_id] ~ dnorm( 0 , sigma_g ),\n",
    "        # hyper-priors\n",
    "        a_bar ~ dnorm( 0 , 1.5 ),\n",
    "        sigma_a ~ dexp(1),\n",
    "        sigma_g ~ dexp(1)\n",
    "    ) , data=dat_list , chains=4 , cores=4 , log_lik=TRUE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "precis( m13.4 , depth=2 ) %>% round(2)\n",
    "plot( precis(m13.4,depth=2) ) # also plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ll end up with 2000 samples from 4 independent chains. As always, be sure to inspect the trace plots and the diagnostics. As soon as you start trusting the machine, the machine will betray your trust. In this case, you might see a warning about divergent transitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in traceplot(m13.4): object 'm13.4' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in traceplot(m13.4): object 'm13.4' not found\nTraceback:\n",
      "1. traceplot(m13.4)"
     ]
    }
   ],
   "source": [
    "traceplot( m13.4 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a consequence, adding block to this model hasn’t added a lot of overfitting risk. Let’s compare the model with only varying intercepts on actor to the model with both kinds of varying intercepts. **<font color = 'purple'>The model that ignores block is: </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## R code 13.23\n",
    "set.seed(14)\n",
    "m13.5 <- ulam(\n",
    "    alist(\n",
    "        pulled_left ~ dbinom( 1 , p ) ,\n",
    "        logit(p) <- a[actor] + b[treatment] ,\n",
    "        b[treatment] ~ dnorm( 0 , 0.5 ),\n",
    "        a[actor] ~ dnorm( a_bar , sigma_a ),\n",
    "        a_bar ~ dnorm( 0 , 1.5 ),\n",
    "        sigma_a ~ dexp(1)\n",
    "    ) , data=dat_list , chains=4 , cores=4 , log_lik=TRUE )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data{\n",
      "    int block_id[504];\n",
      "    int pulled_left[504];\n",
      "    int treatment[504];\n",
      "    int actor[504];\n",
      "}\n",
      "parameters{\n",
      "    vector[4] b;\n",
      "    vector[7] a;\n",
      "    real a_bar;\n",
      "    real<lower=0> sigma_a;\n",
      "}\n",
      "model{\n",
      "    vector[504] p;\n",
      "    sigma_a ~ exponential( 1 );\n",
      "    a_bar ~ normal( 0 , 1.5 );\n",
      "    a ~ normal( a_bar , sigma_a );\n",
      "    b ~ normal( 0 , 0.5 );\n",
      "    for ( i in 1:504 ) {\n",
      "        p[i] = a[actor[i]] + b[treatment[i]];\n",
      "        p[i] = inv_logit(p[i]);\n",
      "    }\n",
      "    pulled_left ~ binomial( 1 , p );\n",
      "}\n",
      "generated quantities{\n",
      "    vector[504] log_lik;\n",
      "    vector[504] p;\n",
      "    for ( i in 1:504 ) {\n",
      "        p[i] = a[actor[i]] + b[treatment[i]];\n",
      "        p[i] = inv_logit(p[i]);\n",
      "    }\n",
      "    for ( i in 1:504 ) log_lik[i] = binomial_lpmf( pulled_left[i] | 1 , p[i] );\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m13.5 %>% stancode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color = 'purple'>Comparing to the model with both clusters: </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>WAIC</th><th scope=col>pWAIC</th><th scope=col>dWAIC</th><th scope=col>weight</th><th scope=col>SE</th><th scope=col>dSE</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>m13.5</th><td>530.96</td><td> 8.45 </td><td>0.00  </td><td>0.65  </td><td>19.23 </td><td> NA   </td></tr>\n",
       "\t<tr><th scope=row>m13.4</th><td>532.24</td><td>10.58 </td><td>1.28  </td><td>0.35  </td><td>19.35 </td><td>1.6   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       "  & WAIC & pWAIC & dWAIC & weight & SE & dSE\\\\\n",
       "\\hline\n",
       "\tm13.5 & 530.96 &  8.45  & 0.00   & 0.65   & 19.23  &  NA   \\\\\n",
       "\tm13.4 & 532.24 & 10.58  & 1.28   & 0.35   & 19.35  & 1.6   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | WAIC | pWAIC | dWAIC | weight | SE | dSE |\n",
       "|---|---|---|---|---|---|---|\n",
       "| m13.5 | 530.96 |  8.45  | 0.00   | 0.65   | 19.23  |  NA    |\n",
       "| m13.4 | 532.24 | 10.58  | 1.28   | 0.35   | 19.35  | 1.6    |\n",
       "\n"
      ],
      "text/plain": [
       "      WAIC   pWAIC dWAIC weight SE    dSE\n",
       "m13.5 530.96  8.45 0.00  0.65   19.23  NA\n",
       "m13.4 532.24 10.58 1.28  0.35   19.35 1.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare( m13.4 , m13.5 ) %>% round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color = 'purple'>While m13.4 has 7 more parameters than m13.5 does, it has only about 2.5 more effective parameters. Why? </font>** \n",
    "\n",
    "* Because the posterior distribution for sigma_g ended up close to zero. This means each of the 6 g parameters is strongly shrunk towards zero—they are relatively inflexible. \n",
    "\n",
    "\n",
    "* In contrast, the a parameters are shrunk towards zero much less, because the estimated variation across actors is much larger, resulting in less shrinkage. <font color = 'blue'>But as a consequence, each of the a parameters contributes much more to the pWAIC value</font>.\n",
    "\n",
    "**<font color = 'purple'>You might also notice that the difference in WAIC between these models is small </font>**, only 2. This is especially small compared the standard deviation of the difference, 1.6. These two models imply nearly identical predictions, and so their expected out-of-sample accuracy is nearly identical. <font color = 'blue'>The block parameters have been shrunk so much towards zero that they do very little work in the model.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Even more clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## R code 13.21\n",
    "library(rethinking)\n",
    "data(chimpanzees)\n",
    "d <- chimpanzees\n",
    "d$treatment <- 1 + d$prosoc_left + 2*d$condition\n",
    "\n",
    "dat_list <- list(\n",
    "    pulled_left = d$pulled_left,\n",
    "    actor = d$actor,\n",
    "    block_id = d$block,\n",
    "    treatment = as.integer(d$treatment) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## R code 13.25\n",
    "set.seed(15)\n",
    "m13.6 <- ulam(\n",
    "    alist(\n",
    "        pulled_left ~ dbinom( 1 , p ) ,\n",
    "        logit(p) <- a[actor] + g[block_id] + b[treatment] ,\n",
    "        b[treatment] ~ dnorm( 0 , sigma_b ),\n",
    "        a[actor] ~ dnorm( a_bar , sigma_a ),\n",
    "        g[block_id] ~ dnorm( 0 , sigma_g ),\n",
    "        a_bar ~ dnorm( 0 , 1.5 ),\n",
    "        sigma_a ~ dexp(1),\n",
    "        sigma_g ~ dexp(1),\n",
    "        sigma_b ~ dexp(1)\n",
    "    ) , data=dat_list , chains=4 , cores=4 , log_lik=TRUE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"There were 7 divergent transitions after warmup. Increasing adapt_delta above 0.95 may help. See\n",
      "http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\"Warning message:\n",
      "\"Examine the pairs() plot to diagnose sampling problems\n",
      "\""
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in coeftab(m13.4, m13.6): object 'm13.4' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in coeftab(m13.4, m13.6): object 'm13.4' not found\nTraceback:\n",
      "1. coeftab(m13.4, m13.6)"
     ]
    }
   ],
   "source": [
    "coeftab(m13.4,m13.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divergent transitions and non-centered priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust target acceptance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in class(fit) %in% c(\"map2stan\", \"ulam\"): object 'm13.4' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in class(fit) %in% c(\"map2stan\", \"ulam\"): object 'm13.4' not found\nTraceback:\n",
      "1. divergent(m13.4)",
      "2. class(fit) %in% c(\"map2stan\", \"ulam\")"
     ]
    }
   ],
   "source": [
    "divergent(m13.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(13)\n",
    "m13.4b <- ulam( m13.4 , chains=4 , cores=4 , control=list(adapt_delta=0.99) )\n",
    "divergent(m13.4b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m13.4b %>% precis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reparameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in file(con, \"w\"):\n",
      "\"cannot open file 'C:\\Users\\bings\\AppData\\Local\\Temp\\Rtmp8YnaDH\\file2efc16573b1a': No such file or directory\""
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in file(con, \"w\"): cannot open the connection\n",
     "output_type": "error",
     "traceback": [
      "Error in file(con, \"w\"): cannot open the connection\nTraceback:\n",
      "1. ulam(alist(pulled_left ~ dbinom(1, p), logit(p) <- a_bar + z[actor] * \n .     sigma_a + x[block_id] * sigma_g + b[treatment], b[treatment] ~ \n .     dnorm(0, 0.5), z[actor] ~ dnorm(0, 1), x[block_id] ~ dnorm(0, \n .     1), a_bar ~ dnorm(0, 1.5), sigma_a ~ dexp(1), sigma_g ~ dexp(1)), \n .     data = dat_list, chains = 4, cores = 4)",
      "2. stan(model_code = model_code, data = data, pars = use_pars, chains = chains, \n .     cores = cores, iter = iter, control = control, ...)",
      "3. stan_model(file, model_name = model_name, model_code = model_code, \n .     stanc_ret = NULL, boost_lib = boost_lib, eigen_lib = eigen_lib, \n .     save_dso = save_dso, verbose = verbose)",
      "4. writeLines(model_code, con = tf)",
      "5. file(con, \"w\")"
     ]
    }
   ],
   "source": [
    "## R code 13.28\n",
    "set.seed(13)\n",
    "m13.4nc <- ulam(\n",
    "    alist(\n",
    "        pulled_left ~ dbinom( 1 , p ) ,\n",
    "        logit(p) <- a_bar + z[actor]*sigma_a + x[block_id]*sigma_g + b[treatment] ,\n",
    "        b[treatment] ~ dnorm( 0 , 0.5 ),\n",
    "        z[actor] ~ dnorm( 0 , 1 ),\n",
    "        x[block_id] ~ dnorm( 0 , 1 ),\n",
    "        a_bar ~ dnorm( 0 , 1.5 ),\n",
    "        sigma_a ~ dexp(1),\n",
    "        sigma_g ~ dexp(1)\n",
    "    ) , data=dat_list , chains=4 , cores=4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## R code 13.29\n",
    "neff_c <- precis( m13.4 , depth=2 )[['n_eff']]\n",
    "neff_nc <- precis( m13.4nc , depth=2 )[['n_eff']]\n",
    "par_names <- rownames( precis( m13.4 , depth=2 ) )\n",
    "neff_table <- cbind( neff_c , neff_nc )\n",
    "rownames(neff_table) <- par_names\n",
    "neff_table %>% t() %>% round()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilevel posterior predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color = 'purple' style='background-color: lightyellow'>We’ll construct posterior predictions (retrodictions), using both the automated link approach and doing it from scratch, so there is no confusion.</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior prediction for same clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code needed to compute posterior predictions is just like the code from Chapter 11. Here it is again, **<font color = 'purple'>computing and plotting posterior predictions for actor number 2: </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Link version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in link(m13.4, data = d_pred): object 'm13.4' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in link(m13.4, data = d_pred): object 'm13.4' not found\nTraceback:\n",
      "1. link(m13.4, data = d_pred)"
     ]
    }
   ],
   "source": [
    "## R code 13.30\n",
    "chimp <- 2\n",
    "d_pred <- list(\n",
    "    actor = rep(chimp,4),\n",
    "    treatment = 1:4,\n",
    "    block_id = rep(1,4)\n",
    ")\n",
    "p <- link( m13.4 , data=d_pred )\n",
    "p_mu <- apply( p , 2 , mean )\n",
    "p_ci <- apply( p , 2 , PI )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### non-link version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color = 'purple'>To construct the same calculations without using link </font>**, we just have to remember the model. The only difficulty is that when we work with the samples from the posterior, the varying intercepts will be a matrix of samples. Let’s take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in extract.samples(m13.4): object 'm13.4' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in extract.samples(m13.4): object 'm13.4' not found\nTraceback:\n",
      "1. extract.samples(m13.4)"
     ]
    }
   ],
   "source": [
    "post <- extract.samples(m13.4)\n",
    "str(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post$a %>% head(2)\n",
    "\n",
    "post$b %>% head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The a matrix has samples on the rows and actors on the columns. So to plot, for example, the density for actor 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cell_style": "split",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in dens(post$a[, 5]): object 'post' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in dens(post$a[, 5]): object 'post' not found\nTraceback:\n",
      "1. dens(post$a[, 5])"
     ]
    }
   ],
   "source": [
    "dens( post$a[,5] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "The `[,5]` means “all samples for actor 5.”\n",
    "\n",
    "**<font color = 'purple'>To construct posterior predictions, we build our own link function. </font>** \n",
    "\n",
    "<font color = 'blue'>I’ll use the with function here, so we don’t have to keep typing post$ before every parameter name:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## R code 13.33\n",
    "p_link <- function( treatment , actor=1 , block_id=1 ) {\n",
    "    logodds <- with( post , a[,actor] + g[,block_id] + b[,treatment] )\n",
    "    return( inv_logit(logodds) )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`logodds <- post$a[,actor] + post$g[,block_id] + post$b[,treatment]`\n",
    "\n",
    "same meaning as the `with` statement line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear model is identical to the one used to define the model, but with a single comma added inside the brackets after a. Now to compute predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in with(post, a[, actor] + g[, block_id] + b[, treatment]): object 'post' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in with(post, a[, actor] + g[, block_id] + b[, treatment]): object 'post' not found\nTraceback:\n",
      "1. sapply(1:4, function(i) p_link(i, actor = 2, block_id = 1))",
      "2. lapply(X = X, FUN = FUN, ...)",
      "3. FUN(X[[i]], ...)",
      "4. p_link(i, actor = 2, block_id = 1)   # at line 2 of file <text>",
      "5. with(post, a[, actor] + g[, block_id] + b[, treatment])   # at line 3 of file <text>"
     ]
    }
   ],
   "source": [
    "## R code 13.34\n",
    "p_raw <- sapply( 1:4 , function(i) p_link( i , actor=2 , block_id=1 ) )\n",
    "p_mu <- apply( p_raw , 2 , mean )\n",
    "p_ci <- apply( p_raw , 2 , PI )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At some point, you will have to work with a model that link will mangle. At that time, you can return to this section and peer hard at the code above and still make progress. No matter what the model is, if it is a Bayesian model, then it is generative. This means that predictions are made by pushing samples up through the model to get distributions of predictions. Then you summarize the distributions to summarize the predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior prediction for new clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color = 'purple'>let’s see how to construct posterior predictions for a new, previously unobserved average actor </font>**. \n",
    "\n",
    "* By “average,” I mean an individual chimpanzee with an intercept exactly at a_bar ($\\bar{α}$), the population mean. Since there is uncertainty about the population mean, there is still uncertainty about this average individual’s intercept. But as you’ll see, the uncertainty is much smaller than it really should be, if we wish to honestly represent the problem of what to expect from a new individual. \n",
    "\n",
    "What we need is our own link function, but now with twist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## R code 13.35\n",
    "p_link_abar <- function( treatment ) {\n",
    "    logodds <- with( post , a_bar + b[,treatment] )\n",
    "    return( inv_logit(logodds) )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the function ignores block. This is because we are extrapolating to new blocks,\n",
    "so we assume the average block effect is about zero (which it was in the sample). Call this\n",
    "function and summarize just as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in with(post, a_bar + b[, treatment]): object 'post' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in with(post, a_bar + b[, treatment]): object 'post' not found\nTraceback:\n",
      "1. sapply(1:4, function(i) p_link_abar(i))",
      "2. lapply(X = X, FUN = FUN, ...)",
      "3. FUN(X[[i]], ...)",
      "4. p_link_abar(i)   # at line 3 of file <text>",
      "5. with(post, a_bar + b[, treatment])   # at line 3 of file <text>"
     ]
    }
   ],
   "source": [
    "\n",
    "## R code 13.36\n",
    "p_raw <- sapply( 1:4 , function(i) p_link_abar( i ) )\n",
    "p_mu <- apply( p_raw , 2 , mean )\n",
    "p_ci <- apply( p_raw , 2 , PI )\n",
    "\n",
    "plot( NULL , xlab=\"treatment\" , ylab=\"proportion pulled left\" ,\n",
    "    ylim=c(0,1) , xaxt=\"n\" , xlim=c(1,4) )\n",
    "axis( 1 , at=1:4 , labels=c(\"R/N\",\"L/N\",\"R/P\",\"L/P\") )\n",
    "lines( 1:4 , p_mu )\n",
    "shade( p_ci , 1:4 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gray region shows the 80% compatibility interval for an actor with an average intercept. This kind of calculation makes it easy to see the impact of prosoc_left, as well as uncertainty about where the average is, but it doesn’t show the variation among actors.\n",
    "\n",
    "To show the variation among actors, we’ll need to use sigma_a in the calculation. First we simply use rnorm to sample some random chimpanzees, using mean a_bar and standard deviation sigma_a. Then we write a link function that references those simulated chimpanzees, not the ones in the posterior. \n",
    "\n",
    "* It’s important to do the chimpanzee sampling outside the link function, because we want to reference the same simulate chimpanzee, whichever treatment we consider. \n",
    "\n",
    "This is the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in with(post, rnorm(length(post$a_bar), a_bar, sigma_a)): object 'post' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in with(post, rnorm(length(post$a_bar), a_bar, sigma_a)): object 'post' not found\nTraceback:\n",
      "1. with(post, rnorm(length(post$a_bar), a_bar, sigma_a))"
     ]
    }
   ],
   "source": [
    "\n",
    "## R code 13.37\n",
    "a_sim <- with( post , rnorm( length(post$a_bar) , a_bar , sigma_a ) )\n",
    "p_link_asim <- function( treatment ) {\n",
    "    logodds <- with( post , a_sim + b[,treatment] )\n",
    "    return( inv_logit(logodds) )\n",
    "}\n",
    "p_raw_asim <- sapply( 1:4 , function(i) p_link_asim( i ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## R code 13.38\n",
    "plot( NULL , xlab=\"treatment\" , ylab=\"proportion pulled left\" ,\n",
    "    ylim=c(0,1) , xaxt=\"n\" , xlim=c(1,4) )\n",
    "axis( 1 , at=1:4 , labels=c(\"R/N\",\"L/N\",\"R/P\",\"L/P\") )\n",
    "for ( i in 1:100 ) lines( 1:4 , p_raw_asim[i,] , col=col.alpha(\"black\",0.25) , lwd=2 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-- Attaching packages --------------------------------------- tidyverse 1.2.1 --\n",
      "v tibble  2.0.1       v purrr   0.3.0  \n",
      "v tidyr   0.8.2       v dplyr   0.8.0.1\n",
      "v readr   1.3.1       v stringr 1.4.0  \n",
      "v tibble  2.0.1       v forcats 0.4.0  \n",
      "Warning message:\n",
      "\"package 'tibble' was built under R version 3.5.2\"Warning message:\n",
      "\"package 'readr' was built under R version 3.5.2\"Warning message:\n",
      "\"package 'purrr' was built under R version 3.5.2\"Warning message:\n",
      "\"package 'dplyr' was built under R version 3.5.2\"Warning message:\n",
      "\"package 'stringr' was built under R version 3.5.2\"Warning message:\n",
      "\"package 'forcats' was built under R version 3.5.2\"-- Conflicts ------------------------------------------ tidyverse_conflicts() --\n",
      "x tidyr::extract() masks rstan::extract()\n",
      "x dplyr::filter()  masks stats::filter()\n",
      "x dplyr::lag()     masks stats::lag()\n",
      "x purrr::map()     masks rethinking::map()\n"
     ]
    }
   ],
   "source": [
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(rethinking)\n",
    "data(reedfrogs)\n",
    "d <- reedfrogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t48 obs. of  5 variables:\n",
      " $ density : int  10 10 10 10 10 10 10 10 10 10 ...\n",
      " $ pred    : Factor w/ 2 levels \"no\",\"pred\": 1 1 1 1 1 1 1 1 2 2 ...\n",
      " $ size    : Factor w/ 2 levels \"big\",\"small\": 1 1 1 1 2 2 2 2 1 1 ...\n",
      " $ surv    : int  9 10 7 10 9 9 10 9 4 9 ...\n",
      " $ propsurv: num  0.9 1 0.7 1 0.9 0.9 1 0.9 0.4 0.9 ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>density</th><th scope=col>pred</th><th scope=col>size</th><th scope=col>surv</th><th scope=col>propsurv</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>10   </td><td>no   </td><td>big  </td><td> 9   </td><td>0.9  </td></tr>\n",
       "\t<tr><td>10   </td><td>no   </td><td>big  </td><td>10   </td><td>1.0  </td></tr>\n",
       "\t<tr><td>10   </td><td>no   </td><td>big  </td><td> 7   </td><td>0.7  </td></tr>\n",
       "\t<tr><td>10   </td><td>no   </td><td>big  </td><td>10   </td><td>1.0  </td></tr>\n",
       "\t<tr><td>10   </td><td>no   </td><td>small</td><td> 9   </td><td>0.9  </td></tr>\n",
       "\t<tr><td>10   </td><td>no   </td><td>small</td><td> 9   </td><td>0.9  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " density & pred & size & surv & propsurv\\\\\n",
       "\\hline\n",
       "\t 10    & no    & big   &  9    & 0.9  \\\\\n",
       "\t 10    & no    & big   & 10    & 1.0  \\\\\n",
       "\t 10    & no    & big   &  7    & 0.7  \\\\\n",
       "\t 10    & no    & big   & 10    & 1.0  \\\\\n",
       "\t 10    & no    & small &  9    & 0.9  \\\\\n",
       "\t 10    & no    & small &  9    & 0.9  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| density | pred | size | surv | propsurv |\n",
       "|---|---|---|---|---|\n",
       "| 10    | no    | big   |  9    | 0.9   |\n",
       "| 10    | no    | big   | 10    | 1.0   |\n",
       "| 10    | no    | big   |  7    | 0.7   |\n",
       "| 10    | no    | big   | 10    | 1.0   |\n",
       "| 10    | no    | small |  9    | 0.9   |\n",
       "| 10    | no    | small |  9    | 0.9   |\n",
       "\n"
      ],
      "text/plain": [
       "  density pred size  surv propsurv\n",
       "1 10      no   big    9   0.9     \n",
       "2 10      no   big   10   1.0     \n",
       "3 10      no   big    7   0.7     \n",
       "4 10      no   big   10   1.0     \n",
       "5 10      no   small  9   0.9     \n",
       "6 10      no   small  9   0.9     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "str(d)\n",
    "d %>% head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d$pred <- ifelse( d$pred==\"no\" , 0 , 1 )\n",
    "d$big <- ifelse( d$size==\"big\" , 1 , 0 )\n",
    "d$tank <- 1:nrow(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     3
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAMPLING FOR MODEL '134938cb467d54dc5d6211d037aee09f' NOW (CHAIN 1).\n",
      "Chain 1: \n",
      "Chain 1: Gradient evaluation took 0 seconds\n",
      "Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 1: Adjust your expectations accordingly!\n",
      "Chain 1: \n",
      "Chain 1: \n",
      "Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 1: \n",
      "Chain 1:  Elapsed Time: 0.446 seconds (Warm-up)\n",
      "Chain 1:                0.526 seconds (Sampling)\n",
      "Chain 1:                0.972 seconds (Total)\n",
      "Chain 1: \n",
      "\n",
      "SAMPLING FOR MODEL '134938cb467d54dc5d6211d037aee09f' NOW (CHAIN 2).\n",
      "Chain 2: \n",
      "Chain 2: Gradient evaluation took 0 seconds\n",
      "Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 2: Adjust your expectations accordingly!\n",
      "Chain 2: \n",
      "Chain 2: \n",
      "Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 2: \n",
      "Chain 2:  Elapsed Time: 0.537 seconds (Warm-up)\n",
      "Chain 2:                0.353 seconds (Sampling)\n",
      "Chain 2:                0.89 seconds (Total)\n",
      "Chain 2: \n",
      "\n",
      "SAMPLING FOR MODEL '134938cb467d54dc5d6211d037aee09f' NOW (CHAIN 3).\n",
      "Chain 3: \n",
      "Chain 3: Gradient evaluation took 0 seconds\n",
      "Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 3: Adjust your expectations accordingly!\n",
      "Chain 3: \n",
      "Chain 3: \n",
      "Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 3: \n",
      "Chain 3:  Elapsed Time: 0.568 seconds (Warm-up)\n",
      "Chain 3:                0.398 seconds (Sampling)\n",
      "Chain 3:                0.966 seconds (Total)\n",
      "Chain 3: \n",
      "\n",
      "SAMPLING FOR MODEL '134938cb467d54dc5d6211d037aee09f' NOW (CHAIN 4).\n",
      "Chain 4: \n",
      "Chain 4: Gradient evaluation took 0.001 seconds\n",
      "Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 10 seconds.\n",
      "Chain 4: Adjust your expectations accordingly!\n",
      "Chain 4: \n",
      "Chain 4: \n",
      "Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 4: \n",
      "Chain 4:  Elapsed Time: 0.491 seconds (Warm-up)\n",
      "Chain 4:                0.414 seconds (Sampling)\n",
      "Chain 4:                0.905 seconds (Total)\n",
      "Chain 4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing WAIC\n"
     ]
    }
   ],
   "source": [
    "m0 <- map2stan(\n",
    "    alist(\n",
    "        surv ~ dbinom(density,p),\n",
    "        logit(p) <- a_tank[tank],\n",
    "        a_tank[tank] ~ dnorm(a,sigma_tank),\n",
    "        a ~ dnorm(0,10),\n",
    "        sigma_tank ~ dcauchy(0,1)\n",
    "    ),\n",
    "    data=d , chains=4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAMPLING FOR MODEL '8ee51b6da32fa6dcc1741095e3c2b4fd' NOW (CHAIN 1).\n",
      "Chain 1: \n",
      "Chain 1: Gradient evaluation took 0 seconds\n",
      "Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 1: Adjust your expectations accordingly!\n",
      "Chain 1: \n",
      "Chain 1: \n",
      "Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 1: \n",
      "Chain 1:  Elapsed Time: 2.019 seconds (Warm-up)\n",
      "Chain 1:                1.892 seconds (Sampling)\n",
      "Chain 1:                3.911 seconds (Total)\n",
      "Chain 1: \n",
      "\n",
      "SAMPLING FOR MODEL '8ee51b6da32fa6dcc1741095e3c2b4fd' NOW (CHAIN 2).\n",
      "Chain 2: \n",
      "Chain 2: Gradient evaluation took 0 seconds\n",
      "Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 2: Adjust your expectations accordingly!\n",
      "Chain 2: \n",
      "Chain 2: \n",
      "Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 2: \n",
      "Chain 2:  Elapsed Time: 1.883 seconds (Warm-up)\n",
      "Chain 2:                1.828 seconds (Sampling)\n",
      "Chain 2:                3.711 seconds (Total)\n",
      "Chain 2: \n",
      "\n",
      "SAMPLING FOR MODEL '8ee51b6da32fa6dcc1741095e3c2b4fd' NOW (CHAIN 3).\n",
      "Chain 3: \n",
      "Chain 3: Gradient evaluation took 0 seconds\n",
      "Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 3: Adjust your expectations accordingly!\n",
      "Chain 3: \n",
      "Chain 3: \n",
      "Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 3: \n",
      "Chain 3:  Elapsed Time: 1.964 seconds (Warm-up)\n",
      "Chain 3:                1.312 seconds (Sampling)\n",
      "Chain 3:                3.276 seconds (Total)\n",
      "Chain 3: \n",
      "\n",
      "SAMPLING FOR MODEL '8ee51b6da32fa6dcc1741095e3c2b4fd' NOW (CHAIN 4).\n",
      "Chain 4: \n",
      "Chain 4: Gradient evaluation took 0 seconds\n",
      "Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 4: Adjust your expectations accordingly!\n",
      "Chain 4: \n",
      "Chain 4: \n",
      "Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 4: \n",
      "Chain 4:  Elapsed Time: 1.714 seconds (Warm-up)\n",
      "Chain 4:                2.15 seconds (Sampling)\n",
      "Chain 4:                3.864 seconds (Total)\n",
      "Chain 4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing WAIC\n"
     ]
    }
   ],
   "source": [
    "m_p <- map2stan( \n",
    "    alist(\n",
    "        surv ~ dbinom(density,p),\n",
    "        logit(p) <- a_tank[tank] + bp*pred,\n",
    "        bp ~ dnorm(0,1),\n",
    "        a_tank[tank] ~ dnorm(a,sigma_tank),\n",
    "        a ~ dnorm(0,10),\n",
    "        sigma_tank ~ dcauchy(0,1)\n",
    "    ),\n",
    "    data=d , chains=4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAMPLING FOR MODEL 'de7f0492e5174e0ea6dd9848e77b71ec' NOW (CHAIN 1).\n",
      "Chain 1: \n",
      "Chain 1: Gradient evaluation took 0 seconds\n",
      "Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 1: Adjust your expectations accordingly!\n",
      "Chain 1: \n",
      "Chain 1: \n",
      "Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 1: \n",
      "Chain 1:  Elapsed Time: 0.585 seconds (Warm-up)\n",
      "Chain 1:                0.754 seconds (Sampling)\n",
      "Chain 1:                1.339 seconds (Total)\n",
      "Chain 1: \n",
      "\n",
      "SAMPLING FOR MODEL 'de7f0492e5174e0ea6dd9848e77b71ec' NOW (CHAIN 2).\n",
      "Chain 2: \n",
      "Chain 2: Gradient evaluation took 0 seconds\n",
      "Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 2: Adjust your expectations accordingly!\n",
      "Chain 2: \n",
      "Chain 2: \n",
      "Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 2: \n",
      "Chain 2:  Elapsed Time: 0.651 seconds (Warm-up)\n",
      "Chain 2:                0.377 seconds (Sampling)\n",
      "Chain 2:                1.028 seconds (Total)\n",
      "Chain 2: \n",
      "\n",
      "SAMPLING FOR MODEL 'de7f0492e5174e0ea6dd9848e77b71ec' NOW (CHAIN 3).\n",
      "Chain 3: \n",
      "Chain 3: Gradient evaluation took 0 seconds\n",
      "Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 3: Adjust your expectations accordingly!\n",
      "Chain 3: \n",
      "Chain 3: \n",
      "Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 3: \n",
      "Chain 3:  Elapsed Time: 0.63 seconds (Warm-up)\n",
      "Chain 3:                0.529 seconds (Sampling)\n",
      "Chain 3:                1.159 seconds (Total)\n",
      "Chain 3: \n",
      "\n",
      "SAMPLING FOR MODEL 'de7f0492e5174e0ea6dd9848e77b71ec' NOW (CHAIN 4).\n",
      "Chain 4: \n",
      "Chain 4: Gradient evaluation took 0 seconds\n",
      "Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 4: Adjust your expectations accordingly!\n",
      "Chain 4: \n",
      "Chain 4: \n",
      "Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 4: \n",
      "Chain 4:  Elapsed Time: 0.714 seconds (Warm-up)\n",
      "Chain 4:                0.851 seconds (Sampling)\n",
      "Chain 4:                1.565 seconds (Total)\n",
      "Chain 4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing WAIC\n"
     ]
    }
   ],
   "source": [
    "m_b <- map2stan( \n",
    "    alist(\n",
    "        surv ~ dbinom(density,p),\n",
    "        logit(p) <- a_tank[tank] + bb*big,\n",
    "        bb ~ dnorm(0,1),\n",
    "        a_tank[tank] ~ dnorm(a,sigma_tank),\n",
    "        a ~ dnorm(0,10),\n",
    "        sigma_tank ~ dcauchy(0,1)\n",
    "    ),\n",
    "    data=d , chains=4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAMPLING FOR MODEL 'e19577fc1514bee1955b27ed9ba845ec' NOW (CHAIN 1).\n",
      "Chain 1: \n",
      "Chain 1: Gradient evaluation took 0 seconds\n",
      "Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 1: Adjust your expectations accordingly!\n",
      "Chain 1: \n",
      "Chain 1: \n",
      "Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 1: \n",
      "Chain 1:  Elapsed Time: 1.011 seconds (Warm-up)\n",
      "Chain 1:                0.948 seconds (Sampling)\n",
      "Chain 1:                1.959 seconds (Total)\n",
      "Chain 1: \n",
      "\n",
      "SAMPLING FOR MODEL 'e19577fc1514bee1955b27ed9ba845ec' NOW (CHAIN 2).\n",
      "Chain 2: \n",
      "Chain 2: Gradient evaluation took 0 seconds\n",
      "Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 2: Adjust your expectations accordingly!\n",
      "Chain 2: \n",
      "Chain 2: \n",
      "Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 2: \n",
      "Chain 2:  Elapsed Time: 0.971 seconds (Warm-up)\n",
      "Chain 2:                1.403 seconds (Sampling)\n",
      "Chain 2:                2.374 seconds (Total)\n",
      "Chain 2: \n",
      "\n",
      "SAMPLING FOR MODEL 'e19577fc1514bee1955b27ed9ba845ec' NOW (CHAIN 3).\n",
      "Chain 3: \n",
      "Chain 3: Gradient evaluation took 0 seconds\n",
      "Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 3: Adjust your expectations accordingly!\n",
      "Chain 3: \n",
      "Chain 3: \n",
      "Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 3: \n",
      "Chain 3:  Elapsed Time: 0.982 seconds (Warm-up)\n",
      "Chain 3:                0.881 seconds (Sampling)\n",
      "Chain 3:                1.863 seconds (Total)\n",
      "Chain 3: \n",
      "\n",
      "SAMPLING FOR MODEL 'e19577fc1514bee1955b27ed9ba845ec' NOW (CHAIN 4).\n",
      "Chain 4: \n",
      "Chain 4: Gradient evaluation took 0 seconds\n",
      "Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 4: Adjust your expectations accordingly!\n",
      "Chain 4: \n",
      "Chain 4: \n",
      "Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 4: \n",
      "Chain 4:  Elapsed Time: 1.187 seconds (Warm-up)\n",
      "Chain 4:                1.596 seconds (Sampling)\n",
      "Chain 4:                2.783 seconds (Total)\n",
      "Chain 4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing WAIC\n"
     ]
    }
   ],
   "source": [
    "m_p_b <- map2stan( \n",
    "    alist(\n",
    "        surv ~ dbinom(density,p),\n",
    "        logit(p) <- a_tank[tank] + bp*pred + bb*big,\n",
    "        c(bp,bb) ~ dnorm(0,1),\n",
    "        a_tank[tank] ~ dnorm(a,sigma_tank),\n",
    "        a ~ dnorm(0,10),\n",
    "        sigma_tank ~ dcauchy(0,1)\n",
    "    ),\n",
    "    data=d , chains=4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAMPLING FOR MODEL '4127bc9e8f7e25c7e77b1c35b368d93e' NOW (CHAIN 1).\n",
      "Chain 1: \n",
      "Chain 1: Gradient evaluation took 0 seconds\n",
      "Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 1: Adjust your expectations accordingly!\n",
      "Chain 1: \n",
      "Chain 1: \n",
      "Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 1: \n",
      "Chain 1:  Elapsed Time: 1.431 seconds (Warm-up)\n",
      "Chain 1:                1.464 seconds (Sampling)\n",
      "Chain 1:                2.895 seconds (Total)\n",
      "Chain 1: \n",
      "\n",
      "SAMPLING FOR MODEL '4127bc9e8f7e25c7e77b1c35b368d93e' NOW (CHAIN 2).\n",
      "Chain 2: \n",
      "Chain 2: Gradient evaluation took 0 seconds\n",
      "Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 2: Adjust your expectations accordingly!\n",
      "Chain 2: \n",
      "Chain 2: \n",
      "Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 2: \n",
      "Chain 2:  Elapsed Time: 1.565 seconds (Warm-up)\n",
      "Chain 2:                1.719 seconds (Sampling)\n",
      "Chain 2:                3.284 seconds (Total)\n",
      "Chain 2: \n",
      "\n",
      "SAMPLING FOR MODEL '4127bc9e8f7e25c7e77b1c35b368d93e' NOW (CHAIN 3).\n",
      "Chain 3: \n",
      "Chain 3: Gradient evaluation took 0 seconds\n",
      "Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 3: Adjust your expectations accordingly!\n",
      "Chain 3: \n",
      "Chain 3: \n",
      "Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 3: \n",
      "Chain 3:  Elapsed Time: 1.592 seconds (Warm-up)\n",
      "Chain 3:                1.716 seconds (Sampling)\n",
      "Chain 3:                3.308 seconds (Total)\n",
      "Chain 3: \n",
      "\n",
      "SAMPLING FOR MODEL '4127bc9e8f7e25c7e77b1c35b368d93e' NOW (CHAIN 4).\n",
      "Chain 4: \n",
      "Chain 4: Gradient evaluation took 0 seconds\n",
      "Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 4: Adjust your expectations accordingly!\n",
      "Chain 4: \n",
      "Chain 4: \n",
      "Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 4: \n",
      "Chain 4:  Elapsed Time: 1.576 seconds (Warm-up)\n",
      "Chain 4:                1.168 seconds (Sampling)\n",
      "Chain 4:                2.744 seconds (Total)\n",
      "Chain 4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing WAIC\n"
     ]
    }
   ],
   "source": [
    "m_p_b_pb <- map2stan(\n",
    "    alist(\n",
    "        surv ~ dbinom(density,p),\n",
    "        logit(p) <- a_tank[tank] + bp*pred + bb*big + bpb*pred*big,\n",
    "        c(bp,bb,bpb) ~ dnorm(0,1),\n",
    "        a_tank[tank] ~ dnorm(a,sigma_tank),\n",
    "        a ~ dnorm(0,10),\n",
    "        sigma_tank ~ dcauchy(0,1)\n",
    "    ),\n",
    "    data=d , chains=4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           m0      m_p     m_b     m_p_b   m_p_b_pb\n",
       "a_tank[1]     2.15    2.00    2.49    2.30    2.39 \n",
       "a_tank[2]     3.11    2.94    3.35    3.25    3.28 \n",
       "a_tank[3]     1.00    0.84    1.34    1.20    1.25 \n",
       "a_tank[4]     3.09    2.96    3.36    3.22    3.31 \n",
       "a_tank[5]     2.15    2.00    2.22    2.07    2.11 \n",
       "a_tank[6]     2.17    1.99    2.19    2.07    2.11 \n",
       "a_tank[7]     3.10    2.93    3.19    3.05    3.11 \n",
       "a_tank[8]     2.17    2.00    2.20    2.06    2.14 \n",
       "a_tank[9]    -0.17   -0.33    0.17    0.02    0.09 \n",
       "a_tank[10]    2.15    1.97    2.47    2.31    2.40 \n",
       "a_tank[11]    1.01    0.85    1.35    1.20    1.23 \n",
       "a_tank[12]    0.59    0.44    0.94    0.77    0.84 \n",
       "a_tank[13]    1.01    0.86    1.05    0.91    0.97 \n",
       "a_tank[14]    0.20    0.03    0.23    0.11    0.14 \n",
       "a_tank[15]    2.14    1.98    2.18    2.08    2.13 \n",
       "a_tank[16]    2.12    1.98    2.20    2.09    2.13 \n",
       "a_tank[17]    2.92    2.76    3.24    3.11    3.15 \n",
       "a_tank[18]    2.39    2.24    2.73    2.59    2.64 \n",
       "a_tank[19]    2.02    1.85    2.37    2.21    2.26 \n",
       "a_tank[20]    3.69    3.50    4.00    3.82    3.91 \n",
       "a_tank[21]    2.41    2.22    2.45    2.31    2.36 \n",
       "a_tank[22]    2.40    2.25    2.44    2.31    2.35 \n",
       "a_tank[23]    2.41    2.25    2.45    2.33    2.36 \n",
       "a_tank[24]    1.71    1.55    1.74    1.61    1.65 \n",
       "a_tank[25]   -1.00   -1.16   -0.65   -0.80   -0.75 \n",
       "a_tank[26]    0.16    0.00    0.51    0.36    0.43 \n",
       "a_tank[27]   -1.43   -1.60   -1.08   -1.24   -1.16 \n",
       "a_tank[28]   -0.47   -0.63   -0.12   -0.27   -0.21 \n",
       "a_tank[29]    0.16    0.00    0.18    0.06    0.10 \n",
       "a_tank[30]    1.45    1.30    1.47    1.35    1.39 \n",
       "a_tank[31]   -0.64   -0.80   -0.63   -0.74   -0.70 \n",
       "a_tank[32]   -0.30   -0.47   -0.29   -0.41   -0.37 \n",
       "a_tank[33]    3.19    3.06    3.54    3.39    3.44 \n",
       "a_tank[34]    2.72    2.54    3.05    2.89    2.97 \n",
       "a_tank[35]    2.71    2.57    3.06    2.90    2.95 \n",
       "a_tank[36]    2.07    1.91    2.42    2.26    2.32 \n",
       "a_tank[37]    2.07    1.91    2.09    1.95    2.01 \n",
       "a_tank[38]    3.93    3.78    4.00    3.85    3.90 \n",
       "a_tank[39]    2.72    2.55    2.76    2.63    2.68 \n",
       "a_tank[40]    2.35    2.20    2.37    2.25    2.30 \n",
       "a_tank[41]   -1.81   -1.97   -1.45   -1.61   -1.56 \n",
       "a_tank[42]   -0.58   -0.73   -0.21   -0.37   -0.30 \n",
       "a_tank[43]   -0.45   -0.61   -0.10   -0.24   -0.18 \n",
       "a_tank[44]   -0.34   -0.50    0.03   -0.13   -0.06 \n",
       "a_tank[45]    0.58    0.42    0.58    0.47    0.51 \n",
       "a_tank[46]   -0.57   -0.73   -0.56   -0.68   -0.64 \n",
       "a_tank[47]    2.06    1.91    2.09    1.96    2.01 \n",
       "a_tank[48]    0.00   -0.15    0.02   -0.11   -0.07 \n",
       "a             1.39    1.23    1.57    1.43    1.48 \n",
       "sigma_tank    1.63    1.63    1.63    1.63    1.63 \n",
       "bp              NA    0.16      NA    0.12    0.08 \n",
       "bb              NA      NA   -0.36   -0.33   -0.19 \n",
       "bpb             NA      NA      NA      NA   -0.17 \n",
       "nobs            48      48      48      48      48 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " coeftab(m0,m_p,m_b,m_p_b,m_p_b_pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48 vector or matrix parameters hidden. Use depth=2 to show them.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>mean</th><th scope=col>sd</th><th scope=col>5.5%</th><th scope=col>94.5%</th><th scope=col>n_eff</th><th scope=col>Rhat</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>bp</th><td> 0.08  </td><td>0.95   </td><td>-1.48  </td><td>1.57   </td><td> 153.15</td><td>1.02   </td></tr>\n",
       "\t<tr><th scope=row>bb</th><td>-0.19  </td><td>0.74   </td><td>-1.36  </td><td>1.00   </td><td>1302.01</td><td>1.00   </td></tr>\n",
       "\t<tr><th scope=row>bpb</th><td>-0.17  </td><td>0.74   </td><td>-1.34  </td><td>0.99   </td><td>1246.70</td><td>1.00   </td></tr>\n",
       "\t<tr><th scope=row>a</th><td> 1.48  </td><td>1.00   </td><td>-0.09  </td><td>3.11   </td><td> 164.11</td><td>1.02   </td></tr>\n",
       "\t<tr><th scope=row>sigma_tank</th><td> 1.63  </td><td>0.23   </td><td> 1.30  </td><td>2.01   </td><td>1288.07</td><td>1.00   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       "  & mean & sd & 5.5\\% & 94.5\\% & n\\_eff & Rhat\\\\\n",
       "\\hline\n",
       "\tbp &  0.08   & 0.95    & -1.48   & 1.57    &  153.15 & 1.02   \\\\\n",
       "\tbb & -0.19   & 0.74    & -1.36   & 1.00    & 1302.01 & 1.00   \\\\\n",
       "\tbpb & -0.17   & 0.74    & -1.34   & 0.99    & 1246.70 & 1.00   \\\\\n",
       "\ta &  1.48   & 1.00    & -0.09   & 3.11    &  164.11 & 1.02   \\\\\n",
       "\tsigma\\_tank &  1.63   & 0.23    &  1.30   & 2.01    & 1288.07 & 1.00   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | mean | sd | 5.5% | 94.5% | n_eff | Rhat |\n",
       "|---|---|---|---|---|---|---|\n",
       "| bp |  0.08   | 0.95    | -1.48   | 1.57    |  153.15 | 1.02    |\n",
       "| bb | -0.19   | 0.74    | -1.36   | 1.00    | 1302.01 | 1.00    |\n",
       "| bpb | -0.17   | 0.74    | -1.34   | 0.99    | 1246.70 | 1.00    |\n",
       "| a |  1.48   | 1.00    | -0.09   | 3.11    |  164.11 | 1.02    |\n",
       "| sigma_tank |  1.63   | 0.23    |  1.30   | 2.01    | 1288.07 | 1.00    |\n",
       "\n"
      ],
      "text/plain": [
       "           mean  sd   5.5%  94.5% n_eff   Rhat\n",
       "bp          0.08 0.95 -1.48 1.57   153.15 1.02\n",
       "bb         -0.19 0.74 -1.36 1.00  1302.01 1.00\n",
       "bpb        -0.17 0.74 -1.34 0.99  1246.70 1.00\n",
       "a           1.48 1.00 -0.09 3.11   164.11 1.02\n",
       "sigma_tank  1.63 0.23  1.30 2.01  1288.07 1.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precis(m_p_b_pb) %>% round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# ---\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Use extract.samples and extract.prior to return lists of samples for posterior and prior distributions, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "504"
      ],
      "text/latex": [
       "504"
      ],
      "text/markdown": [
       "504"
      ],
      "text/plain": [
       "[1] 504"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "504"
      ],
      "text/latex": [
       "504"
      ],
      "text/markdown": [
       "504"
      ],
      "text/plain": [
       "[1] 504"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ERROR",
     "evalue": "Error in eval(lhs, parent, parent): object 'p' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(lhs, parent, parent): object 'p' not found\nTraceback:\n",
      "1. p %>% head",
      "2. eval(lhs, parent, parent)",
      "3. eval(lhs, parent, parent)"
     ]
    }
   ],
   "source": [
    "# dat_list %>% head\n",
    "dat_list$pulled_left %>% length\n",
    "dat_list$pulled_left %>% length\n",
    "p %>% head\n",
    "p %>% dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## R code 13.21\n",
    "# library(rethinking)\n",
    "data(chimpanzees)\n",
    "d <- chimpanzees\n",
    "d$treatment <- 1 + d$prosoc_left + 2*d$condition\n",
    "\n",
    "dat_list <- list(\n",
    "    pulled_left = d$pulled_left,\n",
    "    actor = d$actor,\n",
    "    block_id = d$block,\n",
    "    treatment = as.integer(d$treatment) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>18.7</li>\n",
       "\t<li>14.3</li>\n",
       "\t<li>10.4</li>\n",
       "\t<li>10.4</li>\n",
       "\t<li>14.7</li>\n",
       "\t<li>19.2</li>\n",
       "\t<li>15.8</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 18.7\n",
       "\\item 14.3\n",
       "\\item 10.4\n",
       "\\item 10.4\n",
       "\\item 14.7\n",
       "\\item 19.2\n",
       "\\item 15.8\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 18.7\n",
       "2. 14.3\n",
       "3. 10.4\n",
       "4. 10.4\n",
       "5. 14.7\n",
       "6. 19.2\n",
       "7. 15.8\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 18.7 14.3 10.4 10.4 14.7 19.2 15.8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>18.7</li>\n",
       "\t<li>14.3</li>\n",
       "\t<li>10.4</li>\n",
       "\t<li>10.4</li>\n",
       "\t<li>14.7</li>\n",
       "\t<li>19.2</li>\n",
       "\t<li>15.8</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 18.7\n",
       "\\item 14.3\n",
       "\\item 10.4\n",
       "\\item 10.4\n",
       "\\item 14.7\n",
       "\\item 19.2\n",
       "\\item 15.8\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 18.7\n",
       "2. 14.3\n",
       "3. 10.4\n",
       "4. 10.4\n",
       "5. 14.7\n",
       "6. 19.2\n",
       "7. 15.8\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 18.7 14.3 10.4 10.4 14.7 19.2 15.8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with(mtcars, mpg[cyl == 8  &  disp > 350])\n",
    "    # is the same as, but nicer than\n",
    "\n",
    "mtcars$mpg[mtcars$cyl == 8  &  mtcars$disp > 350]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many functions that work on data frames and take a data argument so that you don't need to retype the name of the data frame for every time you reference a column. lm, plot.formula, subset, transform are just a few examples.\n",
    "\n",
    "with is a general purpose wrapper to let you use any function as if it had a data argument.\n",
    "\n",
    "Using the mtcars data set, we could fit a model with or without using the data argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is obviously annoying\n",
    "mod = lm(mtcars$mpg ~ mtcars$cyl + mtcars$disp + mtcars$wt)\n",
    "\n",
    "# this is nicer\n",
    "mod = lm(mpg ~ cyl + disp + wt, data = mtcars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if (for some strange reason) we wanted to find the mean of cyl + disp + wt, there is a problem because mean doesn't have a data argument like lm does. This is the issue that `with` addresses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without with(), we would be stuck here:\n",
    "z = mean(mtcars$cyl + mtcars$disp + mtcars$wt)\n",
    "\n",
    "# using with(), we can clean this up:\n",
    "z = with(mtcars, mean(cyl + disp + wt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Overthinking: Repeating the pond simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Overthinking**: Repeating the pond simulation. This model samples pretty quickly. Compiling the model takes up most of the execution time. Luckily the compilation only has to be done once. Then you can pass new data to the compiled model and get new estimates. Once you’ve compiled m13.3 once, you can use this code to re-simulate ponds and sample from the new posterior, without waiting for the model to compile again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in is(fit, \"stanfit\"): object 'm13.3' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in is(fit, \"stanfit\"): object 'm13.3' not found\nTraceback:\n",
      "1. stan(fit = m13.3@stanfit, data = newdat, chains = 4)",
      "2. is(fit, \"stanfit\")"
     ]
    }
   ],
   "source": [
    "a <- 1.5\n",
    "sigma <- 1.5\n",
    "nponds <- 60\n",
    "Ni <- as.integer( rep( c(5,10,25,35) , each=15 ) )\n",
    "a_pond <- rnorm( nponds , mean=a , sd=sigma )\n",
    "dsim <- data.frame( pond=1:nponds , Ni=Ni , true_a=a_pond )\n",
    "dsim$Si <- rbinom( nponds,prob=inv_logit( dsim$true_a ),size=dsim$Ni )\n",
    "dsim$p_nopool <- dsim$Si / dsim$Ni\n",
    "newdat <- list(Si=dsim$Si,Ni=dsim$Ni,pond=1:nponds)\n",
    "m13.3new <- stan( fit=m13.3@stanfit , data=newdat , chains=4 )\n",
    "\n",
    "post <- extract.samples( m13.3new )\n",
    "dsim$p_partpool <- apply( inv_logit(post$a_pond) , 2 , mean )\n",
    "dsim$p_true <- inv_logit( dsim$true_a )\n",
    "nopool_error <- abs( dsim$p_nopool - dsim$p_true )\n",
    "partpool_error <- abs( dsim$p_partpool - dsim$p_true )\n",
    "plot( 1:60 , nopool_error , xlab=\"pond\" , ylab=\"absolute error\" , col=rangi2 , pch=16 )\n",
    "points( 1:60 , partpool_error )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### rnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>2.06984355023629</li>\n",
       "\t<li>0.65174195352594</li>\n",
       "\t<li>-0.320667146703585</li>\n",
       "\t<li>-0.546452388907434</li>\n",
       "\t<li>-0.624199425056786</li>\n",
       "\t<li>1.11663295436727</li>\n",
       "\t<li>-0.338138930902573</li>\n",
       "\t<li>1.82075139674913</li>\n",
       "\t<li>1.60083533335132</li>\n",
       "\t<li>2.78495266949782</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2.06984355023629\n",
       "\\item 0.65174195352594\n",
       "\\item -0.320667146703585\n",
       "\\item -0.546452388907434\n",
       "\\item -0.624199425056786\n",
       "\\item 1.11663295436727\n",
       "\\item -0.338138930902573\n",
       "\\item 1.82075139674913\n",
       "\\item 1.60083533335132\n",
       "\\item 2.78495266949782\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2.06984355023629\n",
       "2. 0.65174195352594\n",
       "3. -0.320667146703585\n",
       "4. -0.546452388907434\n",
       "5. -0.624199425056786\n",
       "6. 1.11663295436727\n",
       "7. -0.338138930902573\n",
       "8. 1.82075139674913\n",
       "9. 1.60083533335132\n",
       "10. 2.78495266949782\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1]  2.0698436  0.6517420 -0.3206671 -0.5464524 -0.6241994  1.1166330\n",
       " [7] -0.3381389  1.8207514  1.6008353  2.7849527"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnorm( 10 , mean = 1.5 , sd=1.5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### log odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "see chapter 11\n",
    "\n",
    "* A unit change in xi may produce a larger or smaller change in the probability pi, depending upon how far from zero the log-odds are. \n",
    "\n",
    "For example, in Figure 10.7, <font color = 'blue'> when x = 0 the linear model has a value of zero on the log-odds scale. A halfunit increase in x results in about a 0.25 increase in probability. But each addition half-unit will produce less and less of an increase in probability, until any increase is vanishingly small.</font> \n",
    "\n",
    "* And if you think about it, a good model of probability needs to behave this way. When an event is almost guaranteed to happen, its probability cannot increase very much, no matter how important the predictor may be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src='pics/Snap32.png' alt='Drawing' style='width:425pt'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Probabilities from density curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "https://www.khanacademy.org/math/statistics-probability/random-variables-stats-library/random-variables-continuous/v/probabilities-from-density-curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Curve Function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "https://stat.ethz.ch/R-manual/R-devel/library/graphics/html/curve.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "*The function or expression expr (for curve) or function x (for plot) is evaluated at n points equally spaced over the range [from, to]. The points determined in this way are then plotted.\n",
    "\n",
    "* If either from or to is NULL, it defaults to the corresponding element of xlim if that is not NULL.\n",
    "\n",
    "* For curve(add = NA) and curve(add = TRUE) the defaults are taken from the x-limits used for the previous plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Why QUAP fails, MCMC succeeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Overthinking**: QUAP fails, MCMC succeeds. Why doesn’t simple quadratic approximation, using for example quap, work with multilevel models? When a prior is itself a function of parameters, there are two levels of uncertainty. This means that the probability of the data, conditional on the parameters, must average over each level. Ordinary quadratic approximation cannot handle the averaging in the likelihood, because in general it’s not possible to derive an analytical solution. That means there is no unified function for calculating the log-posterior. So your computer cannot directly find its minimum (the maximum of the posterior). Some other computational approach is needed. It is possible to extend the mode-finding optimization strategy to these models, but we don’t want to be stuck with optimization in general. One reason is that the posterior of these models is routinely non-Gaussian. More generally, as models become more complex, a phenomenon known as concentration of measure guarantees that the posterior mode will be far from the posterior median. So we really need to give up optimization as a strategy. One robust solution is MCMC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A Gaussian approximation is called “quadratic approximation” because the logarithm of a Gaussian distribution forms a parabola. And a parabola is a quadratic function. So this approximation essentially represents any log-posterior with a parabola.\n",
    "\n",
    "For many of the most common procedures in applied statistics—linear regression, for example—the approximation works very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The procedure, which R will happily conduct (QUAC) at your command, contains two steps.\n",
    "\n",
    "* (1) Find the posterior mode. This is usually accomplished by some optimization algorithm, a procedure that virtually “climbs” the posterior distribution, as if it were a mountain. The golem doesn’t know where the peak is, but it does know the slope under its feet. There are many well-developed optimization procedures, most of them more clever than simple hill climbing. But all of them try to find peaks. \n",
    "\n",
    "\n",
    "* (2) Once you find the peak of the posterior, you must estimate the curvature near the peak. This curvature is sufficient to compute a quadratic approximation of the entire posterior distribution. In some cases, these calculations can be done analytically, but usually your computer uses some numerical technique instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Regularizing Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our job is to carefully navigate between overfitting and underfitting. There are two common families of approaches. \n",
    "\n",
    "* The first approach is to use a <span style='background-color: lightgreen'>regularizing prior</span> to <font color = 'blue'>tell the model not to get too excited by the data</font>. This is the same device that non-Bayesian methods refer to as “penalized likelihood.” \n",
    "\n",
    "\n",
    "* The second approach is to use some scoring device, like <span style='background-color: lightgreen'>information criteria</span>, to model the prediction task and estimate predictive accuracy for some purpose. Both families of approaches are routinely used in the natural and social sciences. Furthermore, they can be—maybe should be—used in combination. So it’s worth understanding both, as you’re going to need both at some point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How link works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='pics/SR_r37.png' alt='Drawing' style='width:425pt'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Link example M4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What link will do is take your quap approximation, sample from the posterior distribution, and then compute µ for each case in the data and sample from the posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## R code 4.42\n",
    "# load data again, since it's a long way back\n",
    "library(rethinking)\n",
    "data(Howell1)\n",
    "d <- Howell1\n",
    "d2 <- d[ d$age >= 18 , ]\n",
    "\n",
    "# define the average weight, x-bar\n",
    "xbar <- mean(d2$weight)\n",
    "\n",
    "# fit model\n",
    "m4.3 <- quap(\n",
    "    alist(\n",
    "        height ~ dnorm( mu , sigma ) ,\n",
    "        mu <- a + b*( weight - xbar ) ,\n",
    "        a ~ dnorm( 178 , 20 ) ,\n",
    "        b ~ dlnorm( 0 , 1 ) ,\n",
    "        sigma ~ dunif( 0 , 50 )\n",
    "    ) ,\n",
    "    data=d2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>height</th><th scope=col>weight</th><th scope=col>age</th><th scope=col>male</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>151.765 </td><td>47.82561</td><td>63      </td><td>1       </td></tr>\n",
       "\t<tr><td>139.700 </td><td>36.48581</td><td>63      </td><td>0       </td></tr>\n",
       "\t<tr><td>136.525 </td><td>31.86484</td><td>65      </td><td>0       </td></tr>\n",
       "\t<tr><td>156.845 </td><td>53.04191</td><td>41      </td><td>1       </td></tr>\n",
       "\t<tr><td>145.415 </td><td>41.27687</td><td>51      </td><td>0       </td></tr>\n",
       "\t<tr><td>163.830 </td><td>62.99259</td><td>35      </td><td>1       </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " height & weight & age & male\\\\\n",
       "\\hline\n",
       "\t 151.765  & 47.82561 & 63       & 1       \\\\\n",
       "\t 139.700  & 36.48581 & 63       & 0       \\\\\n",
       "\t 136.525  & 31.86484 & 65       & 0       \\\\\n",
       "\t 156.845  & 53.04191 & 41       & 1       \\\\\n",
       "\t 145.415  & 41.27687 & 51       & 0       \\\\\n",
       "\t 163.830  & 62.99259 & 35       & 1       \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| height | weight | age | male |\n",
       "|---|---|---|---|\n",
       "| 151.765  | 47.82561 | 63       | 1        |\n",
       "| 139.700  | 36.48581 | 63       | 0        |\n",
       "| 136.525  | 31.86484 | 65       | 0        |\n",
       "| 156.845  | 53.04191 | 41       | 1        |\n",
       "| 145.415  | 41.27687 | 51       | 0        |\n",
       "| 163.830  | 62.99259 | 35       | 1        |\n",
       "\n"
      ],
      "text/plain": [
       "  height  weight   age male\n",
       "1 151.765 47.82561 63  1   \n",
       "2 139.700 36.48581 63  0   \n",
       "3 136.525 31.86484 65  0   \n",
       "4 156.845 53.04191 41  1   \n",
       "5 145.415 41.27687 51  0   \n",
       "6 163.830 62.99259 35  1   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>352</li>\n",
       "\t<li>4</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 352\n",
       "\\item 4\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 352\n",
       "2. 4\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 352   4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2 %>% head\n",
    "d2 %>% dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>157.4431</td><td>146.6290</td><td>142.2223</td><td>162.4176</td><td>151.1980</td><td>171.9070</td><td>148.3052</td><td>164.7426</td><td>145.0880</td><td>163.7964</td><td>...     </td><td>153.8204</td><td>157.4972</td><td>149.4137</td><td>150.9817</td><td>150.7654</td><td>156.6861</td><td>144.4933</td><td>161.5795</td><td>163.3909</td><td>161.9310</td></tr>\n",
       "\t<tr><td>157.6083</td><td>146.6297</td><td>142.1560</td><td>162.6584</td><td>151.2682</td><td>172.2921</td><td>148.3314</td><td>165.0188</td><td>145.0653</td><td>164.0582</td><td>...     </td><td>153.9305</td><td>157.6632</td><td>149.4567</td><td>151.0486</td><td>150.8290</td><td>156.8398</td><td>144.4615</td><td>161.8076</td><td>163.6465</td><td>162.1644</td></tr>\n",
       "\t<tr><td>157.7038</td><td>147.9141</td><td>143.9248</td><td>162.2071</td><td>152.0502</td><td>170.7975</td><td>149.4315</td><td>164.3119</td><td>146.5191</td><td>163.4553</td><td>...     </td><td>154.4243</td><td>157.7528</td><td>150.4349</td><td>151.8545</td><td>151.6587</td><td>157.0185</td><td>145.9806</td><td>161.4484</td><td>163.0881</td><td>161.7665</td></tr>\n",
       "\t<tr><td>157.2676</td><td>146.1495</td><td>141.6188</td><td>162.3820</td><td>150.8469</td><td>172.1382</td><td>147.8728</td><td>164.7724</td><td>144.5651</td><td>163.7996</td><td>...     </td><td>153.5430</td><td>157.3232</td><td>149.0124</td><td>150.6245</td><td>150.4022</td><td>156.4894</td><td>143.9536</td><td>161.5203</td><td>163.3826</td><td>161.8817</td></tr>\n",
       "\t<tr><td>156.6896</td><td>145.8559</td><td>141.4411</td><td>161.6732</td><td>150.4331</td><td>171.1798</td><td>147.5351</td><td>164.0024</td><td>144.3121</td><td>163.0545</td><td>...     </td><td>153.0603</td><td>156.7438</td><td>148.6456</td><td>150.2165</td><td>149.9998</td><td>155.9313</td><td>143.7162</td><td>160.8335</td><td>162.6482</td><td>161.1856</td></tr>\n",
       "\t<tr><td>156.6643</td><td>146.9399</td><td>142.9773</td><td>161.1375</td><td>151.0485</td><td>169.6706</td><td>148.4472</td><td>163.2282</td><td>145.5542</td><td>162.3773</td><td>...     </td><td>153.4066</td><td>156.7129</td><td>149.4440</td><td>150.8540</td><td>150.6595</td><td>155.9836</td><td>145.0194</td><td>160.3838</td><td>162.0126</td><td>160.6999</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       "\t 157.4431 & 146.6290 & 142.2223 & 162.4176 & 151.1980 & 171.9070 & 148.3052 & 164.7426 & 145.0880 & 163.7964 & ...      & 153.8204 & 157.4972 & 149.4137 & 150.9817 & 150.7654 & 156.6861 & 144.4933 & 161.5795 & 163.3909 & 161.9310\\\\\n",
       "\t 157.6083 & 146.6297 & 142.1560 & 162.6584 & 151.2682 & 172.2921 & 148.3314 & 165.0188 & 145.0653 & 164.0582 & ...      & 153.9305 & 157.6632 & 149.4567 & 151.0486 & 150.8290 & 156.8398 & 144.4615 & 161.8076 & 163.6465 & 162.1644\\\\\n",
       "\t 157.7038 & 147.9141 & 143.9248 & 162.2071 & 152.0502 & 170.7975 & 149.4315 & 164.3119 & 146.5191 & 163.4553 & ...      & 154.4243 & 157.7528 & 150.4349 & 151.8545 & 151.6587 & 157.0185 & 145.9806 & 161.4484 & 163.0881 & 161.7665\\\\\n",
       "\t 157.2676 & 146.1495 & 141.6188 & 162.3820 & 150.8469 & 172.1382 & 147.8728 & 164.7724 & 144.5651 & 163.7996 & ...      & 153.5430 & 157.3232 & 149.0124 & 150.6245 & 150.4022 & 156.4894 & 143.9536 & 161.5203 & 163.3826 & 161.8817\\\\\n",
       "\t 156.6896 & 145.8559 & 141.4411 & 161.6732 & 150.4331 & 171.1798 & 147.5351 & 164.0024 & 144.3121 & 163.0545 & ...      & 153.0603 & 156.7438 & 148.6456 & 150.2165 & 149.9998 & 155.9313 & 143.7162 & 160.8335 & 162.6482 & 161.1856\\\\\n",
       "\t 156.6643 & 146.9399 & 142.9773 & 161.1375 & 151.0485 & 169.6706 & 148.4472 & 163.2282 & 145.5542 & 162.3773 & ...      & 153.4066 & 156.7129 & 149.4440 & 150.8540 & 150.6595 & 155.9836 & 145.0194 & 160.3838 & 162.0126 & 160.6999\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 157.4431 | 146.6290 | 142.2223 | 162.4176 | 151.1980 | 171.9070 | 148.3052 | 164.7426 | 145.0880 | 163.7964 | ...      | 153.8204 | 157.4972 | 149.4137 | 150.9817 | 150.7654 | 156.6861 | 144.4933 | 161.5795 | 163.3909 | 161.9310 |\n",
       "| 157.6083 | 146.6297 | 142.1560 | 162.6584 | 151.2682 | 172.2921 | 148.3314 | 165.0188 | 145.0653 | 164.0582 | ...      | 153.9305 | 157.6632 | 149.4567 | 151.0486 | 150.8290 | 156.8398 | 144.4615 | 161.8076 | 163.6465 | 162.1644 |\n",
       "| 157.7038 | 147.9141 | 143.9248 | 162.2071 | 152.0502 | 170.7975 | 149.4315 | 164.3119 | 146.5191 | 163.4553 | ...      | 154.4243 | 157.7528 | 150.4349 | 151.8545 | 151.6587 | 157.0185 | 145.9806 | 161.4484 | 163.0881 | 161.7665 |\n",
       "| 157.2676 | 146.1495 | 141.6188 | 162.3820 | 150.8469 | 172.1382 | 147.8728 | 164.7724 | 144.5651 | 163.7996 | ...      | 153.5430 | 157.3232 | 149.0124 | 150.6245 | 150.4022 | 156.4894 | 143.9536 | 161.5203 | 163.3826 | 161.8817 |\n",
       "| 156.6896 | 145.8559 | 141.4411 | 161.6732 | 150.4331 | 171.1798 | 147.5351 | 164.0024 | 144.3121 | 163.0545 | ...      | 153.0603 | 156.7438 | 148.6456 | 150.2165 | 149.9998 | 155.9313 | 143.7162 | 160.8335 | 162.6482 | 161.1856 |\n",
       "| 156.6643 | 146.9399 | 142.9773 | 161.1375 | 151.0485 | 169.6706 | 148.4472 | 163.2282 | 145.5542 | 162.3773 | ...      | 153.4066 | 156.7129 | 149.4440 | 150.8540 | 150.6595 | 155.9836 | 145.0194 | 160.3838 | 162.0126 | 160.6999 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8]    \n",
       "[1,] 157.4431 146.6290 142.2223 162.4176 151.1980 171.9070 148.3052 164.7426\n",
       "[2,] 157.6083 146.6297 142.1560 162.6584 151.2682 172.2921 148.3314 165.0188\n",
       "[3,] 157.7038 147.9141 143.9248 162.2071 152.0502 170.7975 149.4315 164.3119\n",
       "[4,] 157.2676 146.1495 141.6188 162.3820 150.8469 172.1382 147.8728 164.7724\n",
       "[5,] 156.6896 145.8559 141.4411 161.6732 150.4331 171.1798 147.5351 164.0024\n",
       "[6,] 156.6643 146.9399 142.9773 161.1375 151.0485 169.6706 148.4472 163.2282\n",
       "     [,9]     [,10]    [,11] [,12]    [,13]    [,14]    [,15]    [,16]   \n",
       "[1,] 145.0880 163.7964 ...   153.8204 157.4972 149.4137 150.9817 150.7654\n",
       "[2,] 145.0653 164.0582 ...   153.9305 157.6632 149.4567 151.0486 150.8290\n",
       "[3,] 146.5191 163.4553 ...   154.4243 157.7528 150.4349 151.8545 151.6587\n",
       "[4,] 144.5651 163.7996 ...   153.5430 157.3232 149.0124 150.6245 150.4022\n",
       "[5,] 144.3121 163.0545 ...   153.0603 156.7438 148.6456 150.2165 149.9998\n",
       "[6,] 145.5542 162.3773 ...   153.4066 156.7129 149.4440 150.8540 150.6595\n",
       "     [,17]    [,18]    [,19]    [,20]    [,21]   \n",
       "[1,] 156.6861 144.4933 161.5795 163.3909 161.9310\n",
       "[2,] 156.8398 144.4615 161.8076 163.6465 162.1644\n",
       "[3,] 157.0185 145.9806 161.4484 163.0881 161.7665\n",
       "[4,] 156.4894 143.9536 161.5203 163.3826 161.8817\n",
       "[5,] 155.9313 143.7162 160.8335 162.6482 161.1856\n",
       "[6,] 155.9836 145.0194 160.3838 162.0126 160.6999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1000</li>\n",
       "\t<li>352</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1000\n",
       "\\item 352\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1000\n",
       "2. 352\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1000  352"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu <- link( m4.3 ) \n",
    "mu %>% head()\n",
    "\n",
    "mu %>% dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You end up with a big matrix of values of µ. \n",
    "\n",
    "* <font color = 'green'>Each row is a sample from the posterior distribution</font>. The default is 1000 samples, but you can use as many or as few as you like. \n",
    "\n",
    "\n",
    "* <font color = 'green'>Each column is a case (row) in the data; i.e., a value of weight</font>. There are 352 rows in d2, corresponding to 352 individuals. So there are 352 columns in the matrix mu above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Overthinking**: How link works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function link is not really very sophisticated. \n",
    "\n",
    "* All it is doing is using the formula you provided when you fit the model to compute the value of the linear model. It does this for each sample from the posterior distribution, for each case in the data. \n",
    "\n",
    "You could accomplish the same thing for any model, fit by any means, by performing these steps yourself. This is how it’d look for m4.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "post <- extract.samples(m4.3)\n",
    "mu.link <- function(weight) post$a + post$b*( weight - xbar )\n",
    "weight.seq <- seq( from=25 , to=70 , by=1 )\n",
    "mu <- sapply( weight.seq , mu.link )\n",
    "mu.mean <- apply( mu , 2 , mean )\n",
    "mu.HPDI <- apply( mu , 2 , HPDI , prob=0.89 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in png(tf, width, height, \"in\", pointsize, bg, res, antialias = antialias): unable to start png() device\n",
     "output_type": "error",
     "traceback": [
      "Error in png(tf, width, height, \"in\", pointsize, bg, res, antialias = antialias): unable to start png() device\nTraceback:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## R code 4.55\n",
    "# use type=\"n\" to hide raw data\n",
    "plot( height ~ weight , d2 , type=\"n\" )\n",
    "\n",
    "# loop over samples and plot each mu value\n",
    "for ( i in 1:100 )\n",
    "    points( weight.seq , mu[i,] , pch=16 , col=col.alpha(rangi2,0.1) )\n",
    "\n",
    "options(repr.plot.width=6, repr.plot.height=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "## R code 4.56\n",
    "# summarize the distribution of mu\n",
    "mu.mean <- apply( mu , 2 , mean )\n",
    "mu.HPDI <- apply( mu , 2 , HPDI , prob=0.89 )\n",
    "\n",
    "## R code 4.57\n",
    "# plot raw data\n",
    "# fading out points to make line and interval more visible\n",
    "plot( height ~ weight , data=d2 , col=col.alpha(rangi2,0.5) )\n",
    "\n",
    "# plot the MAP line, aka the mean mu for each weight\n",
    "lines( weight.seq , mu.mean )\n",
    "\n",
    "# plot a shaded region for 89% HPDI\n",
    "shade( mu.HPDI , weight.seq )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='pics/SR_r38.png' alt='Drawing' style='width:425pt'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mu.mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>10000</li>\n",
       "\t<li>46</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 10000\n",
       "\\item 46\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 10000\n",
       "2. 46\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 10000    46"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu %>% dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the values in mu.mean and mu.HPDI should be very similar (allowing for simulation variance) to what you got the automated way, using link. \n",
    "\n",
    "Knowing this manual method is useful both for (1) understanding and (2) sheer power. Whatever the model you find yourself with, this approach can be used to generate posterior predictions for any component of it. Automated tools like link save effort, but they are never as flexible as the code you can write yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>135.4750</td><td>136.4390</td><td>137.4031</td><td>138.3671</td><td>139.3311</td><td>140.2951</td><td>141.2592</td><td>142.2232</td><td>143.1872</td><td>144.1513</td><td>...     </td><td>170.1801</td><td>171.1441</td><td>172.1081</td><td>173.0721</td><td>174.0362</td><td>175.0002</td><td>175.9642</td><td>176.9283</td><td>177.8923</td><td>178.8563</td></tr>\n",
       "\t<tr><td>136.3289</td><td>137.2285</td><td>138.1281</td><td>139.0277</td><td>139.9272</td><td>140.8268</td><td>141.7264</td><td>142.6260</td><td>143.5255</td><td>144.4251</td><td>...     </td><td>168.7137</td><td>169.6132</td><td>170.5128</td><td>171.4124</td><td>172.3120</td><td>173.2115</td><td>174.1111</td><td>175.0107</td><td>175.9103</td><td>176.8098</td></tr>\n",
       "\t<tr><td>136.4446</td><td>137.3696</td><td>138.2946</td><td>139.2196</td><td>140.1446</td><td>141.0696</td><td>141.9946</td><td>142.9196</td><td>143.8447</td><td>144.7697</td><td>...     </td><td>169.7448</td><td>170.6698</td><td>171.5948</td><td>172.5198</td><td>173.4448</td><td>174.3698</td><td>175.2948</td><td>176.2198</td><td>177.1448</td><td>178.0698</td></tr>\n",
       "\t<tr><td>135.8260</td><td>136.7810</td><td>137.7359</td><td>138.6909</td><td>139.6458</td><td>140.6008</td><td>141.5557</td><td>142.5107</td><td>143.4656</td><td>144.4205</td><td>...     </td><td>170.2041</td><td>171.1590</td><td>172.1139</td><td>173.0689</td><td>174.0238</td><td>174.9788</td><td>175.9337</td><td>176.8887</td><td>177.8436</td><td>178.7986</td></tr>\n",
       "\t<tr><td>135.8642</td><td>136.8014</td><td>137.7387</td><td>138.6759</td><td>139.6132</td><td>140.5505</td><td>141.4877</td><td>142.4250</td><td>143.3622</td><td>144.2995</td><td>...     </td><td>169.6055</td><td>170.5428</td><td>171.4800</td><td>172.4173</td><td>173.3545</td><td>174.2918</td><td>175.2290</td><td>176.1663</td><td>177.1036</td><td>178.0408</td></tr>\n",
       "\t<tr><td>137.6323</td><td>138.5035</td><td>139.3747</td><td>140.2459</td><td>141.1170</td><td>141.9882</td><td>142.8594</td><td>143.7306</td><td>144.6018</td><td>145.4730</td><td>...     </td><td>168.9949</td><td>169.8661</td><td>170.7373</td><td>171.6085</td><td>172.4797</td><td>173.3508</td><td>174.2220</td><td>175.0932</td><td>175.9644</td><td>176.8356</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{llllllllllllllllllllllllllllllllllllllllllllll}\n",
       "\t 135.4750 & 136.4390 & 137.4031 & 138.3671 & 139.3311 & 140.2951 & 141.2592 & 142.2232 & 143.1872 & 144.1513 & ...      & 170.1801 & 171.1441 & 172.1081 & 173.0721 & 174.0362 & 175.0002 & 175.9642 & 176.9283 & 177.8923 & 178.8563\\\\\n",
       "\t 136.3289 & 137.2285 & 138.1281 & 139.0277 & 139.9272 & 140.8268 & 141.7264 & 142.6260 & 143.5255 & 144.4251 & ...      & 168.7137 & 169.6132 & 170.5128 & 171.4124 & 172.3120 & 173.2115 & 174.1111 & 175.0107 & 175.9103 & 176.8098\\\\\n",
       "\t 136.4446 & 137.3696 & 138.2946 & 139.2196 & 140.1446 & 141.0696 & 141.9946 & 142.9196 & 143.8447 & 144.7697 & ...      & 169.7448 & 170.6698 & 171.5948 & 172.5198 & 173.4448 & 174.3698 & 175.2948 & 176.2198 & 177.1448 & 178.0698\\\\\n",
       "\t 135.8260 & 136.7810 & 137.7359 & 138.6909 & 139.6458 & 140.6008 & 141.5557 & 142.5107 & 143.4656 & 144.4205 & ...      & 170.2041 & 171.1590 & 172.1139 & 173.0689 & 174.0238 & 174.9788 & 175.9337 & 176.8887 & 177.8436 & 178.7986\\\\\n",
       "\t 135.8642 & 136.8014 & 137.7387 & 138.6759 & 139.6132 & 140.5505 & 141.4877 & 142.4250 & 143.3622 & 144.2995 & ...      & 169.6055 & 170.5428 & 171.4800 & 172.4173 & 173.3545 & 174.2918 & 175.2290 & 176.1663 & 177.1036 & 178.0408\\\\\n",
       "\t 137.6323 & 138.5035 & 139.3747 & 140.2459 & 141.1170 & 141.9882 & 142.8594 & 143.7306 & 144.6018 & 145.4730 & ...      & 168.9949 & 169.8661 & 170.7373 & 171.6085 & 172.4797 & 173.3508 & 174.2220 & 175.0932 & 175.9644 & 176.8356\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 135.4750 | 136.4390 | 137.4031 | 138.3671 | 139.3311 | 140.2951 | 141.2592 | 142.2232 | 143.1872 | 144.1513 | ...      | 170.1801 | 171.1441 | 172.1081 | 173.0721 | 174.0362 | 175.0002 | 175.9642 | 176.9283 | 177.8923 | 178.8563 |\n",
       "| 136.3289 | 137.2285 | 138.1281 | 139.0277 | 139.9272 | 140.8268 | 141.7264 | 142.6260 | 143.5255 | 144.4251 | ...      | 168.7137 | 169.6132 | 170.5128 | 171.4124 | 172.3120 | 173.2115 | 174.1111 | 175.0107 | 175.9103 | 176.8098 |\n",
       "| 136.4446 | 137.3696 | 138.2946 | 139.2196 | 140.1446 | 141.0696 | 141.9946 | 142.9196 | 143.8447 | 144.7697 | ...      | 169.7448 | 170.6698 | 171.5948 | 172.5198 | 173.4448 | 174.3698 | 175.2948 | 176.2198 | 177.1448 | 178.0698 |\n",
       "| 135.8260 | 136.7810 | 137.7359 | 138.6909 | 139.6458 | 140.6008 | 141.5557 | 142.5107 | 143.4656 | 144.4205 | ...      | 170.2041 | 171.1590 | 172.1139 | 173.0689 | 174.0238 | 174.9788 | 175.9337 | 176.8887 | 177.8436 | 178.7986 |\n",
       "| 135.8642 | 136.8014 | 137.7387 | 138.6759 | 139.6132 | 140.5505 | 141.4877 | 142.4250 | 143.3622 | 144.2995 | ...      | 169.6055 | 170.5428 | 171.4800 | 172.4173 | 173.3545 | 174.2918 | 175.2290 | 176.1663 | 177.1036 | 178.0408 |\n",
       "| 137.6323 | 138.5035 | 139.3747 | 140.2459 | 141.1170 | 141.9882 | 142.8594 | 143.7306 | 144.6018 | 145.4730 | ...      | 168.9949 | 169.8661 | 170.7373 | 171.6085 | 172.4797 | 173.3508 | 174.2220 | 175.0932 | 175.9644 | 176.8356 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8]    \n",
       "[1,] 135.4750 136.4390 137.4031 138.3671 139.3311 140.2951 141.2592 142.2232\n",
       "[2,] 136.3289 137.2285 138.1281 139.0277 139.9272 140.8268 141.7264 142.6260\n",
       "[3,] 136.4446 137.3696 138.2946 139.2196 140.1446 141.0696 141.9946 142.9196\n",
       "[4,] 135.8260 136.7810 137.7359 138.6909 139.6458 140.6008 141.5557 142.5107\n",
       "[5,] 135.8642 136.8014 137.7387 138.6759 139.6132 140.5505 141.4877 142.4250\n",
       "[6,] 137.6323 138.5035 139.3747 140.2459 141.1170 141.9882 142.8594 143.7306\n",
       "     [,9]     [,10]    [,11] [,12]    [,13]    [,14]    [,15]    [,16]   \n",
       "[1,] 143.1872 144.1513 ...   170.1801 171.1441 172.1081 173.0721 174.0362\n",
       "[2,] 143.5255 144.4251 ...   168.7137 169.6132 170.5128 171.4124 172.3120\n",
       "[3,] 143.8447 144.7697 ...   169.7448 170.6698 171.5948 172.5198 173.4448\n",
       "[4,] 143.4656 144.4205 ...   170.2041 171.1590 172.1139 173.0689 174.0238\n",
       "[5,] 143.3622 144.2995 ...   169.6055 170.5428 171.4800 172.4173 173.3545\n",
       "[6,] 144.6018 145.4730 ...   168.9949 169.8661 170.7373 171.6085 172.4797\n",
       "     [,17]    [,18]    [,19]    [,20]    [,21]   \n",
       "[1,] 175.0002 175.9642 176.9283 177.8923 178.8563\n",
       "[2,] 173.2115 174.1111 175.0107 175.9103 176.8098\n",
       "[3,] 174.3698 175.2948 176.2198 177.1448 178.0698\n",
       "[4,] 174.9788 175.9337 176.8887 177.8436 178.7986\n",
       "[5,] 174.2918 175.2290 176.1663 177.1036 178.0408\n",
       "[6,] 173.3508 174.2220 175.0932 175.9644 176.8356"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu %>% head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### sapply(X, FUN, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'blue'>takes each value in the first argument and passes it into the function in the second argument</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X = a vector (atomic or list) or an expression object. Other objects (including classed objects) will be coerced by base::as.list.\n",
    "\n",
    "FUN = the function to be applied to each element of X: see ‘Details’. In the case of functions like +, %*%, the function name must be backquoted or quoted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### apply(X, MARGIN, FUN, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color = 'purple'>X </font>**\t\n",
    "an array, including a matrix.\n",
    "\n",
    "**<font color = 'purple'>MARGIN </font>**\t\n",
    "a vector giving the subscripts which the function will be applied over. E.g., for a matrix 1 indicates rows, 2 indicates columns, c(1, 2) indicates rows and columns. Where X has named dimnames, it can be a character vector selecting dimension names.\n",
    "\n",
    "**<font color = 'purple'>FUN </font>**\t\n",
    "the function to be applied: see ‘Details’. In the case of functions like +, %*%, etc., the function name must be backquoted or quoted."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
